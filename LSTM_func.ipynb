{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows(sample_data, window_size):\n",
    "    start = 0\n",
    "    while start < sample_data.shape[1]:\n",
    "        yield start, start + window_size\n",
    "        start += (window_size)\n",
    "        \n",
    "def ts_to_supervise(data,window_size,n_var):\n",
    "    \"\"\"\n",
    "        Convert input data into LSTMs data\n",
    "        \n",
    "        args:\n",
    "        window_size : the length of time-series. All input columns must have identical length\n",
    "        n_var : number of features regardless the time-series period\n",
    "        \n",
    "        returns:\n",
    "        result_array : A 3-D LSTMs array \n",
    "        \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    result_array = np.asarray(np.zeros((data.shape[0],window_size,n_var)))\n",
    "    for i in range(0,data.shape[0]):\n",
    "    \n",
    "        segments = None\n",
    "        \n",
    "        for (start, end) in windows(data, window_size):\n",
    "            if (data[:,start:end].shape[1]== (window_size)):\n",
    "                signal = np.asarray(data[i,start:end])\n",
    "                if segments is None:\n",
    "                    segments = signal\n",
    "                else:\n",
    "                    segments = np.vstack([segments, signal])\n",
    "        segments = segments.transpose()\n",
    "\n",
    "        result_array[i,:,:] = segments\n",
    "    return(result_array)\n",
    "\n",
    "def drop_col(columns, col_thresh, sample_x):\n",
    "    \"\"\"\n",
    "        Drop zero-inflation columns\n",
    "    \"\"\"\n",
    "    col_to_drop = []\n",
    "    zero_probs = []\n",
    "    \n",
    "    for col in columns:\n",
    "        \n",
    "        zero_prob = sum((sample_x[col] == 0).astype(int))/len(sample_x[col])\n",
    "        \n",
    "        zero_probs.append(zero_prob)\n",
    "        \n",
    "        if sample_x[col].dtype != 'int64':\n",
    "            sample_x[col].astype('int64')\n",
    "            print(\"[features]: numerize colname names:\" ,col)  \n",
    "        \n",
    "        if zero_prob > col_thresh:\n",
    "            col_to_drop.append(col)\n",
    "            print('[features]:',col, \"has been dropped with zeros more than\", zero_prob)\n",
    "    return col_to_drop, zero_probs\n",
    "\n",
    "def get_feature_name(col_list):\n",
    "    \"\"\"\n",
    "        Get the time-series features' names regardless of the time period\n",
    "    \"\"\"\n",
    "    feature_names =[]\n",
    "    for col in col_list:\n",
    "        feature_name = col.split('_')[0]\n",
    "        feature_names.append(feature_name)\n",
    "    return(feature_names)\n",
    "\n",
    "def features_extract (sample_df, ts_len):\n",
    "    \"\"\"\n",
    "        Filter time-series features from the input data and return a list of those features' names\n",
    "    \"\"\"\n",
    "    raw_features = sample_df.columns\n",
    "    fea_list = get_feature_name(raw_features)\n",
    "\n",
    "    ts_features = []\n",
    "    for col in set(fea_list):\n",
    "        if fea_list.count(col) == ts_len:\n",
    "            ts_features.append(col)\n",
    "    print('[features]: ',len(ts_features),\"time series features founded from data...\")\n",
    "\n",
    "    output_features = []\n",
    "    for feature_name in ts_features:\n",
    "        try:\n",
    "            print('[features]: generating windowed average deltas...',feature_name)\n",
    "            # get the column names\n",
    "            feats = list(sample_df.filter(regex=(feature_name+'*_[0-59]')).columns)\n",
    "            print(len(feats),\"founded\")\n",
    "        except:\n",
    "             print('[features]: Oops! features name not found...')\n",
    "        output_features.append(feats)\n",
    "    output_features = [item for sublist in output_features for item in sublist]\n",
    "    output_features = list(set(output_features))\n",
    "    return(output_features)\n",
    "\n",
    "\n",
    "def train_test_split(sample_data, valsize = 0.05, random_state = 42):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    _, _, train_idx, val_idx = train_test_split(sample_data, sample_data.index, test_size=valsize, random_state=random_state)\n",
    "    \n",
    "    sample_data.ix[train_idx,'split'] = 'Train'\n",
    "    sample_data.ix[val_idx,'split'] = 'Validation'\n",
    "    \n",
    "    print(sample_data['split'].value_counts())\n",
    "    \n",
    "    return(sample_data)\n",
    "\n",
    "def plot_confusion_matrix(truth, predicted, labels={}, save_name='',\n",
    "                          title='Confusion Matrix', norm=1, suppress_values=False,\n",
    "                          diagonal_values=False,\n",
    "                          font_size=10,\n",
    "                          cmin=0,cmax=1,\n",
    "                          cut_off = 1\n",
    "                          ):\n",
    "    # make confusion matrix from truth and predicted for classes\n",
    "    # define the confusion matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    import numpy as np\n",
    "    \n",
    "    conf_mat = confusion_matrix(truth,predicted,labels = labels)\n",
    "    \n",
    "    #normalise\n",
    "    if norm:\n",
    "        conf_mat =  conf_mat.astype('float')/conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    width = np.shape(conf_mat)[1]\n",
    "    height = np.shape(conf_mat)[0]\n",
    "\n",
    "    res = plt.imshow(np.array(conf_mat), cmap=plt.cm.summer, interpolation='nearest')\n",
    "    cb = fig.colorbar(res)\n",
    "    \n",
    "    res.set_clim(cmin, cmax)\n",
    "    \n",
    "    # add number overlay\n",
    "    for i, row in enumerate(conf_mat):\n",
    "        for j, c in enumerate(row):\n",
    "            if (not suppress_values or (diagonal_values and i==j)) and c>0 :\n",
    "                cent = .1\n",
    "                if diagonal_values:\n",
    "                    cent = .3\n",
    "                \n",
    "                if norm:\n",
    "                    d = round(c,2)\n",
    "                    plt.text(j-cent, i+.0, d, fontsize=font_size)\n",
    "                else:\n",
    "                    plt.text(j-cent, i+.0, c, fontsize=font_size)\n",
    "    \n",
    "            if (i==j) and c > cut_off:\n",
    "                cent= 0.3\n",
    "                plt.text(j-cent, i+.0, 'X', fontsize=font_size)\n",
    "\n",
    "    # set axes\n",
    "    plt.xticks(range(len(labels)), labels, rotation = 60, fontsize=font_size)\n",
    "    plt.yticks(range(len(labels)), labels, rotation = 60, fontsize=font_size)\n",
    "    \n",
    "    plt.xlabel('Predicted',fontsize=font_size+4)\n",
    "    plt.ylabel('Truth',fontsize=font_size+4)\n",
    "    plt.title(title,fontsize=font_size+5)\n",
    "\n",
    "    if save_name != '':\n",
    "        plt.savefig(save_name)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_roc(test_y, pred_y, roc_save_name = None):\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(test_y, pred_y[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    if roc_save_name != '':\n",
    "        plt.savefig(roc_save_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0_b</th>\n",
       "      <th>0_ca</th>\n",
       "      <th>0_cec</th>\n",
       "      <th>0_cl</th>\n",
       "      <th>0_cu</th>\n",
       "      <th>0_ec</th>\n",
       "      <th>0_ec_ratio</th>\n",
       "      <th>0_fe</th>\n",
       "      <th>0_k</th>\n",
       "      <th>...</th>\n",
       "      <th>sumSolarRadiation_2016-11-01</th>\n",
       "      <th>sumSolarRadiation_2016-12-01</th>\n",
       "      <th>sz_checkArea</th>\n",
       "      <th>sz_fieldArea</th>\n",
       "      <th>sz_k</th>\n",
       "      <th>sz_n</th>\n",
       "      <th>sz_p</th>\n",
       "      <th>sz_s</th>\n",
       "      <th>sz_yieldTargetFinal</th>\n",
       "      <th>vrCostPerBu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>3526.910000</td>\n",
       "      <td>22.150000</td>\n",
       "      <td>4.513333</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.650000</td>\n",
       "      <td>340.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>138.9708</td>\n",
       "      <td>116.6616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.209251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>0.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>3919.760000</td>\n",
       "      <td>24.263333</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.606667</td>\n",
       "      <td>274.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>138.9708</td>\n",
       "      <td>116.6616</td>\n",
       "      <td>0.637196</td>\n",
       "      <td>30.773239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>3382.855000</td>\n",
       "      <td>20.875000</td>\n",
       "      <td>2.842500</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.715000</td>\n",
       "      <td>284.740000</td>\n",
       "      <td>...</td>\n",
       "      <td>138.9708</td>\n",
       "      <td>116.6616</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>18.274870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>1.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>3858.935000</td>\n",
       "      <td>23.535000</td>\n",
       "      <td>3.696667</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.375000</td>\n",
       "      <td>236.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>138.9708</td>\n",
       "      <td>116.6616</td>\n",
       "      <td>0.683034</td>\n",
       "      <td>18.770088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.767500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>138.9708</td>\n",
       "      <td>116.6616</td>\n",
       "      <td>0.523388</td>\n",
       "      <td>17.326056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>161.5644</td>\n",
       "      <td>118.6272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.752051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>1.251667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>3546.743333</td>\n",
       "      <td>25.123333</td>\n",
       "      <td>17.144000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.603333</td>\n",
       "      <td>329.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>135.4968</td>\n",
       "      <td>100.0836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.729431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>135.4968</td>\n",
       "      <td>100.0836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.494933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>4737.860000</td>\n",
       "      <td>30.560000</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.330000</td>\n",
       "      <td>374.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>142.4196</td>\n",
       "      <td>117.3888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.276372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>5350.590000</td>\n",
       "      <td>34.457500</td>\n",
       "      <td>27.307500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.807500</td>\n",
       "      <td>422.122500</td>\n",
       "      <td>...</td>\n",
       "      <td>142.4196</td>\n",
       "      <td>117.3888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.175425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.686667</td>\n",
       "      <td>5042.463333</td>\n",
       "      <td>33.186667</td>\n",
       "      <td>37.717500</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>485.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>142.4196</td>\n",
       "      <td>117.3888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.569264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>5718.600000</td>\n",
       "      <td>36.070000</td>\n",
       "      <td>8.072500</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.180000</td>\n",
       "      <td>434.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>142.4196</td>\n",
       "      <td>117.3888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.822631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.586667</td>\n",
       "      <td>6012.230000</td>\n",
       "      <td>39.313333</td>\n",
       "      <td>13.532500</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.253333</td>\n",
       "      <td>330.286667</td>\n",
       "      <td>...</td>\n",
       "      <td>142.4196</td>\n",
       "      <td>117.3888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.561272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>2494.066667</td>\n",
       "      <td>16.223333</td>\n",
       "      <td>4.991429</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.183333</td>\n",
       "      <td>387.690000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>32.643764</td>\n",
       "      <td>67.145712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>1.172857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>7093.690000</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>7.347500</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.590000</td>\n",
       "      <td>436.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>157.9140</td>\n",
       "      <td>116.8524</td>\n",
       "      <td>7.521683</td>\n",
       "      <td>19.291305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164.7000</td>\n",
       "      <td>120.9384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>211</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>7075.310000</td>\n",
       "      <td>45.470000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.910000</td>\n",
       "      <td>844.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>305.876970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>212</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>4814.000000</td>\n",
       "      <td>30.950000</td>\n",
       "      <td>11.260000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.060000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>366.478244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323.696623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>215</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>6822.570000</td>\n",
       "      <td>44.460000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.540000</td>\n",
       "      <td>765.610000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>328.985140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>216</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>4953.610000</td>\n",
       "      <td>30.560000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>356.280000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279.164657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>217</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4754.730000</td>\n",
       "      <td>30.210000</td>\n",
       "      <td>6.030000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.630000</td>\n",
       "      <td>419.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.942935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>149.2524</td>\n",
       "      <td>112.1760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.244678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.034563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.115596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.425079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.759345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.427417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.502898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.957336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.192456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.423471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.339010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.895512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.063270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.659601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.366627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.513737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.866665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.574641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.981921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.533911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>174.6396</td>\n",
       "      <td>125.3448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.101229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.501996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169.2792</td>\n",
       "      <td>123.0084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.841481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  1324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       0_b         0_ca      0_cec       0_cl      0_cu  \\\n",
       "0             0  0.285000  3526.910000  22.150000   4.513333  0.765000   \n",
       "1             1  0.503333  3919.760000  24.263333   3.070000  0.636667   \n",
       "2             2       NaN          NaN        NaN        NaN       NaN   \n",
       "3             3  0.460000  3382.855000  20.875000   2.842500  0.560000   \n",
       "4             4  0.485000  3858.935000  23.535000   3.696667  0.855000   \n",
       "5             5       NaN          NaN        NaN        NaN       NaN   \n",
       "6             6       NaN          NaN        NaN        NaN       NaN   \n",
       "7             7       NaN          NaN        NaN        NaN       NaN   \n",
       "8             8       NaN          NaN        NaN        NaN       NaN   \n",
       "9             9       NaN          NaN        NaN        NaN       NaN   \n",
       "10           10       NaN          NaN        NaN        NaN       NaN   \n",
       "11           11       NaN          NaN        NaN        NaN       NaN   \n",
       "12           12       NaN          NaN        NaN        NaN       NaN   \n",
       "13           13       NaN          NaN        NaN        NaN       NaN   \n",
       "14           14       NaN          NaN        NaN        NaN       NaN   \n",
       "15           15       NaN          NaN        NaN   1.767500       NaN   \n",
       "16           16       NaN          NaN        NaN        NaN       NaN   \n",
       "17           17  0.710000  3546.743333  25.123333  17.144000  1.090000   \n",
       "18           18       NaN          NaN        NaN        NaN       NaN   \n",
       "19           19  1.350000  4737.860000  30.560000   9.120000  0.780000   \n",
       "20           20  1.565000  5350.590000  34.457500  27.307500  0.875000   \n",
       "21           21  1.686667  5042.463333  33.186667  37.717500  0.960000   \n",
       "22           22  2.080000  5718.600000  36.070000   8.072500  1.290000   \n",
       "23           23  1.586667  6012.230000  39.313333  13.532500  0.983333   \n",
       "24           24  0.290000  2494.066667  16.223333   4.991429  0.833333   \n",
       "25           25       NaN          NaN        NaN        NaN       NaN   \n",
       "26           26       NaN          NaN        NaN        NaN       NaN   \n",
       "27           27       NaN          NaN        NaN        NaN       NaN   \n",
       "28           28       NaN          NaN        NaN        NaN       NaN   \n",
       "29           29  0.580000  7093.690000  45.600000   7.347500  1.880000   \n",
       "..          ...       ...          ...        ...        ...       ...   \n",
       "240         171       NaN          NaN        NaN        NaN       NaN   \n",
       "241         211  0.790000  7075.310000  45.470000   5.690000  1.830000   \n",
       "242         212  0.530000  4814.000000  30.950000  11.260000  0.960000   \n",
       "243         214       NaN          NaN        NaN   4.350000       NaN   \n",
       "244         215  0.850000  6822.570000  44.460000   5.560000  1.770000   \n",
       "245         216  0.470000  4953.610000  30.560000   6.110000  1.090000   \n",
       "246         217  0.400000  4754.730000  30.210000   6.030000  1.150000   \n",
       "247         218       NaN          NaN        NaN   3.620000       NaN   \n",
       "248         244       NaN          NaN        NaN        NaN       NaN   \n",
       "249         246       NaN          NaN        NaN        NaN       NaN   \n",
       "250         247       NaN          NaN        NaN        NaN       NaN   \n",
       "251         248       NaN          NaN        NaN        NaN       NaN   \n",
       "252         249       NaN          NaN        NaN        NaN       NaN   \n",
       "253         251       NaN          NaN        NaN        NaN       NaN   \n",
       "254         253       NaN          NaN        NaN        NaN       NaN   \n",
       "255         254       NaN          NaN        NaN        NaN       NaN   \n",
       "256         255       NaN          NaN        NaN        NaN       NaN   \n",
       "257         256       NaN          NaN        NaN        NaN       NaN   \n",
       "258         257       NaN          NaN        NaN        NaN       NaN   \n",
       "259         258       NaN          NaN        NaN        NaN       NaN   \n",
       "260         259       NaN          NaN        NaN        NaN       NaN   \n",
       "261         260       NaN          NaN        NaN        NaN       NaN   \n",
       "262         261       NaN          NaN        NaN        NaN       NaN   \n",
       "263         262       NaN          NaN        NaN        NaN       NaN   \n",
       "264         263       NaN          NaN        NaN        NaN       NaN   \n",
       "265         264       NaN          NaN        NaN        NaN       NaN   \n",
       "266         265       NaN          NaN        NaN        NaN       NaN   \n",
       "267         266       NaN          NaN        NaN        NaN       NaN   \n",
       "268         267       NaN          NaN        NaN        NaN       NaN   \n",
       "269         268       NaN          NaN        NaN        NaN       NaN   \n",
       "\n",
       "         0_ec  0_ec_ratio       0_fe         0_k     ...       \\\n",
       "0    0.226667         2.0  35.650000  340.800000     ...        \n",
       "1    0.240000         2.0  56.606667  274.540000     ...        \n",
       "2         NaN         NaN        NaN         NaN     ...        \n",
       "3    0.200000         2.0  43.715000  284.740000     ...        \n",
       "4    0.203333         2.0  39.375000  236.930000     ...        \n",
       "5         NaN         NaN        NaN         NaN     ...        \n",
       "6         NaN         NaN        NaN         NaN     ...        \n",
       "7         NaN         NaN        NaN         NaN     ...        \n",
       "8         NaN         NaN        NaN         NaN     ...        \n",
       "9         NaN         NaN        NaN         NaN     ...        \n",
       "10        NaN         NaN        NaN         NaN     ...        \n",
       "11        NaN         NaN        NaN         NaN     ...        \n",
       "12        NaN         NaN        NaN         NaN     ...        \n",
       "13        NaN         NaN        NaN         NaN     ...        \n",
       "14        NaN         NaN        NaN         NaN     ...        \n",
       "15   0.195000         2.0        NaN         NaN     ...        \n",
       "16        NaN         NaN        NaN         NaN     ...        \n",
       "17   0.724000         2.0  54.603333  329.120000     ...        \n",
       "18        NaN         NaN        NaN         NaN     ...        \n",
       "19   0.390000         2.0  25.330000  374.880000     ...        \n",
       "20   0.760000         2.0  32.807500  422.122500     ...        \n",
       "21   0.967500         2.0  34.113333  485.870000     ...        \n",
       "22   0.967500         2.0  97.180000  434.430000     ...        \n",
       "23   0.980000         2.0  15.253333  330.286667     ...        \n",
       "24   0.210000         2.0  49.183333  387.690000     ...        \n",
       "25        NaN         NaN        NaN         NaN     ...        \n",
       "26        NaN         NaN        NaN         NaN     ...        \n",
       "27        NaN         NaN        NaN         NaN     ...        \n",
       "28        NaN         NaN        NaN         NaN     ...        \n",
       "29   0.727500         2.0  12.590000  436.590000     ...        \n",
       "..        ...         ...        ...         ...     ...        \n",
       "240       NaN         NaN        NaN         NaN     ...        \n",
       "241  0.570000         2.0  22.910000  844.670000     ...        \n",
       "242  0.390000         2.0  23.060000  350.000000     ...        \n",
       "243  0.390000         2.0        NaN         NaN     ...        \n",
       "244  0.480000         2.0  23.540000  765.610000     ...        \n",
       "245  0.260000         2.0  12.810000  356.280000     ...        \n",
       "246  0.270000         2.0  34.630000  419.750000     ...        \n",
       "247  0.460000         2.0        NaN         NaN     ...        \n",
       "248       NaN         NaN        NaN         NaN     ...        \n",
       "249       NaN         NaN        NaN         NaN     ...        \n",
       "250       NaN         NaN        NaN         NaN     ...        \n",
       "251       NaN         NaN        NaN         NaN     ...        \n",
       "252       NaN         NaN        NaN         NaN     ...        \n",
       "253       NaN         NaN        NaN         NaN     ...        \n",
       "254       NaN         NaN        NaN         NaN     ...        \n",
       "255       NaN         NaN        NaN         NaN     ...        \n",
       "256       NaN         NaN        NaN         NaN     ...        \n",
       "257       NaN         NaN        NaN         NaN     ...        \n",
       "258       NaN         NaN        NaN         NaN     ...        \n",
       "259       NaN         NaN        NaN         NaN     ...        \n",
       "260       NaN         NaN        NaN         NaN     ...        \n",
       "261       NaN         NaN        NaN         NaN     ...        \n",
       "262       NaN         NaN        NaN         NaN     ...        \n",
       "263       NaN         NaN        NaN         NaN     ...        \n",
       "264       NaN         NaN        NaN         NaN     ...        \n",
       "265       NaN         NaN        NaN         NaN     ...        \n",
       "266       NaN         NaN        NaN         NaN     ...        \n",
       "267       NaN         NaN        NaN         NaN     ...        \n",
       "268       NaN         NaN        NaN         NaN     ...        \n",
       "269       NaN         NaN        NaN         NaN     ...        \n",
       "\n",
       "     sumSolarRadiation_2016-11-01  sumSolarRadiation_2016-12-01  sz_checkArea  \\\n",
       "0                        138.9708                      116.6616      0.000000   \n",
       "1                        138.9708                      116.6616      0.637196   \n",
       "2                             NaN                           NaN      0.000000   \n",
       "3                        138.9708                      116.6616      0.756918   \n",
       "4                        138.9708                      116.6616      0.683034   \n",
       "5                             NaN                           NaN      0.000000   \n",
       "6                             NaN                           NaN      0.000000   \n",
       "7                             NaN                           NaN      0.000000   \n",
       "8                             NaN                           NaN      0.000000   \n",
       "9                             NaN                           NaN      0.000000   \n",
       "10                            NaN                           NaN      0.000000   \n",
       "11                            NaN                           NaN      0.000000   \n",
       "12                            NaN                           NaN      0.000000   \n",
       "13                            NaN                           NaN      0.000000   \n",
       "14                            NaN                           NaN      0.000000   \n",
       "15                       138.9708                      116.6616      0.523388   \n",
       "16                       161.5644                      118.6272      0.000000   \n",
       "17                       135.4968                      100.0836      0.000000   \n",
       "18                       135.4968                      100.0836      0.000000   \n",
       "19                       142.4196                      117.3888      0.000000   \n",
       "20                       142.4196                      117.3888      0.000000   \n",
       "21                       142.4196                      117.3888      0.000000   \n",
       "22                       142.4196                      117.3888      0.000000   \n",
       "23                       142.4196                      117.3888      0.000000   \n",
       "24                       164.7000                      120.9384     32.643764   \n",
       "25                       164.7000                      120.9384           NaN   \n",
       "26                       164.7000                      120.9384           NaN   \n",
       "27                       164.7000                      120.9384           NaN   \n",
       "28                       164.7000                      120.9384           NaN   \n",
       "29                       157.9140                      116.8524      7.521683   \n",
       "..                            ...                           ...           ...   \n",
       "240                      164.7000                      120.9384           NaN   \n",
       "241                      149.2524                      112.1760      0.000000   \n",
       "242                      149.2524                      112.1760      0.000000   \n",
       "243                      149.2524                      112.1760      0.000000   \n",
       "244                      149.2524                      112.1760      0.000000   \n",
       "245                      149.2524                      112.1760      0.000000   \n",
       "246                      149.2524                      112.1760      0.000000   \n",
       "247                      149.2524                      112.1760      0.000000   \n",
       "248                      169.2792                      123.0084      0.000000   \n",
       "249                      169.2792                      123.0084      0.000000   \n",
       "250                      169.2792                      123.0084      0.000000   \n",
       "251                      169.2792                      123.0084      0.000000   \n",
       "252                      169.2792                      123.0084      0.000000   \n",
       "253                      169.2792                      123.0084      0.000000   \n",
       "254                      169.2792                      123.0084      0.000000   \n",
       "255                      169.2792                      123.0084      0.000000   \n",
       "256                      169.2792                      123.0084      0.000000   \n",
       "257                      169.2792                      123.0084      0.000000   \n",
       "258                      169.2792                      123.0084      0.000000   \n",
       "259                      169.2792                      123.0084      0.000000   \n",
       "260                      169.2792                      123.0084      0.000000   \n",
       "261                      169.2792                      123.0084      0.000000   \n",
       "262                      169.2792                      123.0084      0.000000   \n",
       "263                      169.2792                      123.0084      0.000000   \n",
       "264                      169.2792                      123.0084      0.000000   \n",
       "265                      169.2792                      123.0084      0.000000   \n",
       "266                      169.2792                      123.0084      0.000000   \n",
       "267                      174.6396                      125.3448      0.000000   \n",
       "268                      169.2792                      123.0084      0.000000   \n",
       "269                      169.2792                      123.0084      0.000000   \n",
       "\n",
       "     sz_fieldArea  sz_k        sz_n       sz_p  sz_s  sz_yieldTargetFinal  \\\n",
       "0       11.209251   0.0   92.500000  35.000000   0.0            57.500000   \n",
       "1       30.773239   0.0   92.500000  35.000000   0.0            65.000000   \n",
       "2             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "3       18.274870   0.0   98.333333  35.000000   0.0            63.333333   \n",
       "4       18.770088   0.0   97.000000  35.000000   0.0            66.000000   \n",
       "5             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "6             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "7             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "8             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "9             NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "10            NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "11            NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "12            NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "13            NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "14            NaN   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "15      17.326056   0.0   91.666667  35.000000   0.0            60.833333   \n",
       "16      14.752051   0.0   67.000000  30.000000   0.0            52.500000   \n",
       "17      20.729431   0.0    0.000000  24.857143   0.0            52.500000   \n",
       "18      20.494933   0.0  115.000000  29.200000   0.0            51.000000   \n",
       "19      21.276372   0.0  140.000000  36.300000   0.0            57.000000   \n",
       "20      25.175425   0.0   64.000000  35.000000   0.0            70.000000   \n",
       "21      24.569264   0.0   82.500000  35.000000   0.0            67.500000   \n",
       "22      19.822631   0.0   82.000000  35.000000   0.0            70.000000   \n",
       "23      17.561272   0.0   85.833333  35.000000   0.0            71.666667   \n",
       "24      67.145712   0.0   56.000000  18.750000   0.0            47.750000   \n",
       "25            NaN   NaN         NaN        NaN   NaN                  NaN   \n",
       "26            NaN   NaN         NaN        NaN   NaN                  NaN   \n",
       "27            NaN   NaN         NaN        NaN   NaN                  NaN   \n",
       "28            NaN   NaN         NaN        NaN   NaN                  NaN   \n",
       "29      19.291305   0.0   55.500000  33.333333   0.0            54.000000   \n",
       "..            ...   ...         ...        ...   ...                  ...   \n",
       "240           NaN   NaN         NaN        NaN   NaN                  NaN   \n",
       "241    305.876970   0.0  110.000000  30.000000   0.0            65.000000   \n",
       "242    366.478244   0.0  130.000000  33.000000  18.0            65.000000   \n",
       "243    323.696623   0.0  140.000000  33.000000  20.0            65.000000   \n",
       "244    328.985140   0.0  140.000000  33.000000  20.0            65.000000   \n",
       "245    279.164657   0.0  120.000000  35.000000  10.0            65.000000   \n",
       "246    263.942935   0.0  120.000000  32.000000  10.0            65.000000   \n",
       "247    150.244678   0.0  120.000000  40.000000   0.0            65.000000   \n",
       "248     22.034563   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "249     22.115596   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "250     24.425079   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "251     25.759345   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "252     40.427417   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "253     20.502898   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "254     17.957336   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "255      7.192456   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "256     17.423471   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "257      8.339010   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "258     20.895512   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "259     20.063270   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "260     20.659601   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "261     41.366627   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "262     24.513737   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "263     16.866665   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "264     25.574641   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "265     23.981921   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "266     21.533911   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "267     42.101229   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "268     22.501996   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "269     22.841481   0.0    0.000000   0.000000   0.0                  NaN   \n",
       "\n",
       "     vrCostPerBu  \n",
       "0       0.834000  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3       1.253333  \n",
       "4            NaN  \n",
       "5            NaN  \n",
       "6            NaN  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "9            NaN  \n",
       "10           NaN  \n",
       "11           NaN  \n",
       "12           NaN  \n",
       "13           NaN  \n",
       "14           NaN  \n",
       "15      0.760000  \n",
       "16      1.251667  \n",
       "17           NaN  \n",
       "18           NaN  \n",
       "19      2.462000  \n",
       "20      0.920000  \n",
       "21           NaN  \n",
       "22      1.066000  \n",
       "23           NaN  \n",
       "24      1.172857  \n",
       "25           NaN  \n",
       "26           NaN  \n",
       "27           NaN  \n",
       "28           NaN  \n",
       "29      0.984000  \n",
       "..           ...  \n",
       "240          NaN  \n",
       "241          NaN  \n",
       "242          NaN  \n",
       "243          NaN  \n",
       "244          NaN  \n",
       "245          NaN  \n",
       "246          NaN  \n",
       "247          NaN  \n",
       "248          NaN  \n",
       "249          NaN  \n",
       "250          NaN  \n",
       "251          NaN  \n",
       "252          NaN  \n",
       "253          NaN  \n",
       "254          NaN  \n",
       "255          NaN  \n",
       "256          NaN  \n",
       "257          NaN  \n",
       "258          NaN  \n",
       "259          NaN  \n",
       "260          NaN  \n",
       "261          NaN  \n",
       "262          NaN  \n",
       "263          NaN  \n",
       "264          NaN  \n",
       "265          NaN  \n",
       "266          NaN  \n",
       "267          NaN  \n",
       "268          NaN  \n",
       "269          NaN  \n",
       "\n",
       "[270 rows x 1324 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_processing(data, label, columns, ts_len, col_thresh, random):\n",
    "    \"\"\"\n",
    "        Pre-process the data to LSTMs data\n",
    "        In this function, we clean the input dataset with selected columns, delete those zero-inflation columns\n",
    "        and convert the reserved to LSTMs dataset for LSTM model fitting.\n",
    "        \n",
    "        args:\n",
    "            data : directory of input data\n",
    "            label : name of the column containing respond variable\n",
    "            columns : names of the column of features (must be time series type)\n",
    "            col_thresh : a threshhold value between 0 - 1 for dropping zero-inflation columns\n",
    "            ts_len : length of time series\n",
    "            test : True/False, testing data\n",
    "            \n",
    "        returns:\n",
    "            feature_names_reserve: Features names reserved\n",
    "            feature_names_drop: Features names dropped\n",
    "            train_array: Processed training X\n",
    "            val_array: Processed validation X\n",
    "            test_array: Processed testing X\n",
    "            Y_train: Processed training Y\n",
    "            Y_val: Processed validation Y\n",
    "            Y_test: Processed testing Y\n",
    "            zero_probs: An array of precentage of zeros each columns\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    # Read data\n",
    "    sample_data = data\n",
    "    \n",
    "    # Extract outcome label\n",
    "    sample_y = sample_data[label]\n",
    "\n",
    "    # Extract data with interested features\n",
    "    sample_x = sample_data[columns]\n",
    "    \n",
    "    # Obtain columns with a lot of zero values, col_thresh is the threshold for zero percentage\n",
    "    \n",
    "#     col_to_drop, zero_probs = drop_col(columns, col_thresh, sample_x)\n",
    "     \n",
    "#     sample_x = sample_x.drop(col_to_drop,1)\n",
    "    \n",
    "#     # Obtain dropped feature names\n",
    "#     col_list = list(col_to_drop)\n",
    "#     feature_names_drop = get_feature_name(col_list)     \n",
    "#     print('[features]:',len(set(feature_names_drop)),\"zero-inflation features\")\n",
    "\n",
    "#     # Obtain reserved feature names\n",
    "#     col_list = list(sample_x.columns)\n",
    "#     feature_names_reserve = get_feature_name(col_list)\n",
    "#     print('[features]:',len(set(feature_names_reserve)),\"features will be included in LSTMs model\")\n",
    "    \n",
    "    x_values = sample_x.values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     values = scaler.fit_transform(x_values)\n",
    "#     x_values = scaler.transform(values)\n",
    "    \n",
    "    # Train/test split\n",
    "    sample_data = train_test_split(sample_data, valsize = 0.05, random_state = random)\n",
    "\n",
    "    # Obtain training data  \n",
    "    X_train = x_values[sample_data.split=='Train']\n",
    "    Y_train = sample_y[sample_data.split=='Train']\n",
    "    # convert training data to LSTM data\n",
    "    train_array = ts_to_supervise(X_train,ts_len,47)\n",
    "    \n",
    "    # Obtain validation data    \n",
    "    X_val = x_values[sample_data.split=='Validation']\n",
    "    Y_val = sample_y[sample_data.split=='Validation'] \n",
    "    val_array = ts_to_supervise(X_val,ts_len,47)\n",
    "    \n",
    "    full_x_array = ts_to_supervise(x_values,ts_len,47)\n",
    "    \n",
    "    return full_x_array, train_array, val_array, Y_train, Y_val\n",
    "\n",
    "def fit_lstm(train_x, train_y, val_x, val_y, epochs, batch_size):\n",
    "    \"\"\"\n",
    "        Fit LSTMs model\n",
    "        In this function, we fit the LSTMs model with customized parameters\n",
    "        args:\n",
    "            train_x : training features\n",
    "            train_y : training y\n",
    "            val_x : validation features\n",
    "            val_y : validation y\n",
    "            epochs : number of epoch\n",
    "            batch_size : batch size\n",
    "        returns:\n",
    "            lstm_model : fitted LSTM model\n",
    "    \"\"\"\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM, Dropout\n",
    "    from keras import optimizers\n",
    "    from keras.models import Sequential\n",
    "    \n",
    "    # Initialize model    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4,input_shape=(train_x.shape[1], train_x.shape[2]), return_sequences=False))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    # 128 is the number of hidden units sent forward to the next time step, a.k.a, dimensionality of the output space.\n",
    "    # input_shape is the dimensionality of the input needed to claim in the first layer.\n",
    "    # return sequences is a boolean indicating whether to return the last output in the output sequence, or the full sequence.\n",
    "#     model.add(LSTM(20, input_shape=(train_x.shape[1], train_x.shape[2]),return_sequences=True))\n",
    "#     model.add(LSTM(10, return_sequences=True))\n",
    "#     model.add(LSTM(5, return_sequences=False))\n",
    "\n",
    "    # regular densely-connected NN layer with 2 dimensionality of output space.\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # configure the model for training\n",
    "    # loss is a loss function used in model fitting, we use categorical_crossentropy because we are predicting categorical outcome\n",
    "    # optimizer is determined for compiping a Keras model\n",
    "    # matrics is for evaluation matrics and here we use 'accuracy'\n",
    "#     opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    # summarize the model in table\n",
    "#     model.summary()\n",
    "    \n",
    "    # fit model\n",
    "    lstm_model = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data= (val_x, val_y), verbose=2\n",
    "                           , shuffle=False)\n",
    "    \n",
    "    return(lstm_model)\n",
    "def val_lstm(sample_df, model, x_values, y_values, batch_size, cutoff = 0.5, roc_save_name='', cm_save_name = '', result_csv_save_name = ''):\n",
    "    \"\"\"\n",
    "        Validate LSTMs model\n",
    "        In this function, we validate our fitted LSTMs model with some evaluation plots\n",
    "        args:\n",
    "            model : fitted LSTMs model\n",
    "            test_x : testing features\n",
    "            test_y : testing y\n",
    "            batch_size : batch size\n",
    "            cutoff : predicted y = 1, if Predicted probability > 0.5, else, 0 \n",
    "            roc_save_name : name of saved roc plot\n",
    "            cm_save_name : name of saved confusion matrix plot\n",
    "            result_csv_save_name : name of saved result csv file\n",
    "        returns:\n",
    "            result_df : result csv with predicted probability, category, etc.\n",
    "    \"\"\"\n",
    "   \n",
    "    # get fitted y\n",
    "    pred_y = model.predict(x_values, batch_size=batch_size, verbose=2)\n",
    "    \n",
    "    \n",
    "    # Combine data\n",
    "    result_df = pd.concat([sample_df['serial'],sample_df['split'],pd.Series(y_values, name = 'true_y'),pd.Series(pred_y[:,1], name = 'pred_y')],axis = 1)\n",
    "    \n",
    "    # Write csv\n",
    "    result_df.to_csv(result_csv_save_name, sep = '\\t')\n",
    "    \n",
    "    # draw roc\n",
    "    plot_roc(y_values, pred_y, roc_save_name = roc_save_name)\n",
    "    \n",
    "    # draw confusion matrix\n",
    "    ypred = [[ 1 if x > cutoff else 0 ]for x in pred_y[:,1]]\n",
    "    plot_confusion_matrix(truth = y_values, predicted = ypred,labels=[0,1],save_name=cm_save_name)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features]:  47 time series features founded from data...\n",
      "[features]: generating windowed average deltas... sumNormalIrradiance\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxDewpoint\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... sumDiffuseHorizontalRadiation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgApparentTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgDewpoint\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minRelativeHumidity\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... sumPrecipitation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgAirPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxNormalIrradiance\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxWindSpeed\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minWetBulb\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minDewpoint\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgDiffuseHorizontalRadiation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minWindChill\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgPrecipitation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxMslPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxAirPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgWindSpeed\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... sumHeatIndex\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgWindGust\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxPrecipitation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxWetBulb\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgHeatIndex\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minHeatIndex\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... sumSolarRadiation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgRelativeHumidity\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minApparentTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgCloudCoverage\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minWindGust\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgWindChill\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgNormalIrradiance\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxApparentTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgMslPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgSolarRadiation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... diravgWindDirection\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxHeatIndex\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minAirPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minMslPressure\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxSolarRadiation\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxWindChill\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... avgWetBulb\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... minWindSpeed\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxTemp\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxWindGust\n",
      "24 founded\n",
      "[features]: generating windowed average deltas... maxDiffuseHorizontalRadiation\n",
      "24 founded\n"
     ]
    }
   ],
   "source": [
    "# Noticed that the input features name in data_processing function must be exactly the same as the column name in data.\n",
    "# i.e. \"MaxExternalPressure_00\", \"MaxExternalPressure_01\", ... \"MaxExternalPressure_59\", etc..\n",
    "# Here we manually extract the interested features name ('x_name' below) before running the function.\n",
    "import pandas as pd\n",
    "sample_df = pd.read_csv(\"corrected_yields.csv\")\n",
    "features_list = features_extract(sample_df, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1128/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harryhan\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\harryhan\\Anaconda\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\harryhan\\Anaconda\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train         237\n",
      "Validation     13\n",
      "Name: split, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature processing\n",
    "full_array_x, X_train, X_val, Y_train, Y_val = data_processing(data = df_sub, label = 'Json Yield', columns = features_list, ts_len = 24, col_thresh = 0.5, random = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 4)                 832       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 837\n",
      "Trainable params: 837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 237 samples, validate on 13 samples\n",
      "Epoch 1/500\n",
      " - 4s - loss: 1684501.4921 - val_loss: 1376554.8905\n",
      "Epoch 2/500\n",
      " - 2s - loss: 1154681.5730 - val_loss: 1365076.9314\n",
      "Epoch 3/500\n",
      " - 2s - loss: 1149277.1401 - val_loss: 1354144.7532\n",
      "Epoch 4/500\n",
      " - 2s - loss: 1144122.9382 - val_loss: 1343549.9516\n",
      "Epoch 5/500\n",
      " - 2s - loss: 1139178.0293 - val_loss: 1333280.6840\n",
      "Epoch 6/500\n",
      " - 2s - loss: 1134433.5204 - val_loss: 1323325.9983\n",
      "Epoch 7/500\n",
      " - 2s - loss: 1129881.3476 - val_loss: 1313674.7584\n",
      "Epoch 8/500\n",
      " - 2s - loss: 1125513.2971 - val_loss: 1304316.9818\n",
      "Epoch 9/500\n",
      " - 2s - loss: 1121321.8386 - val_loss: 1295242.8032\n",
      "Epoch 10/500\n",
      " - 2s - loss: 1117299.5271 - val_loss: 1286441.8663\n",
      "Epoch 11/500\n",
      " - 2s - loss: 1113439.4212 - val_loss: 1277905.7154\n",
      "Epoch 12/500\n",
      " - 2s - loss: 1109734.7145 - val_loss: 1269625.2458\n",
      "Epoch 13/500\n",
      " - 2s - loss: 1106179.1457 - val_loss: 1261591.8540\n",
      "Epoch 14/500\n",
      " - 2s - loss: 1102766.3507 - val_loss: 1253797.5138\n",
      "Epoch 15/500\n",
      " - 2s - loss: 1099490.4277 - val_loss: 1246233.6157\n",
      "Epoch 16/500\n",
      " - 2s - loss: 1096345.8770 - val_loss: 1238893.1878\n",
      "Epoch 17/500\n",
      " - 2s - loss: 1093327.0693 - val_loss: 1231768.7548\n",
      "Epoch 18/500\n",
      " - 2s - loss: 1090428.9368 - val_loss: 1224852.8017\n",
      "Epoch 19/500\n",
      " - 2s - loss: 1087646.4902 - val_loss: 1218138.6436\n",
      "Epoch 20/500\n",
      " - 2s - loss: 1084974.8791 - val_loss: 1211619.9850\n",
      "Epoch 21/500\n",
      " - 2s - loss: 1082409.5490 - val_loss: 1205290.0601\n",
      "Epoch 22/500\n",
      " - 2s - loss: 1079946.1107 - val_loss: 1199143.2188\n",
      "Epoch 23/500\n",
      " - 2s - loss: 1077580.6806 - val_loss: 1193172.9772\n",
      "Epoch 24/500\n",
      " - 3s - loss: 1075308.7637 - val_loss: 1187373.9081\n",
      "Epoch 25/500\n",
      " - 2s - loss: 1073126.7487 - val_loss: 1181740.4249\n",
      "Epoch 26/500\n",
      " - 2s - loss: 1071030.9108 - val_loss: 1176267.4567\n",
      "Epoch 27/500\n",
      " - 2s - loss: 1069017.7721 - val_loss: 1170949.5721\n",
      "Epoch 28/500\n",
      " - 2s - loss: 1067083.8388 - val_loss: 1165781.7740\n",
      "Epoch 29/500\n",
      " - 2s - loss: 1065225.8713 - val_loss: 1160759.9405\n",
      "Epoch 30/500\n",
      " - 2s - loss: 1063440.8921 - val_loss: 1155878.8149\n",
      "Epoch 31/500\n",
      " - 2s - loss: 1061725.8741 - val_loss: 1151134.5331\n",
      "Epoch 32/500\n",
      " - 2s - loss: 1060077.8734 - val_loss: 1146522.0625\n",
      "Epoch 33/500\n",
      " - 2s - loss: 1058494.1817 - val_loss: 1142037.5661\n",
      "Epoch 34/500\n",
      " - 2s - loss: 1056972.2546 - val_loss: 1137677.6544\n",
      "Epoch 35/500\n",
      " - 2s - loss: 1055509.5516 - val_loss: 1133437.7206\n",
      "Epoch 36/500\n",
      " - 2s - loss: 1054103.5682 - val_loss: 1129314.4561\n",
      "Epoch 37/500\n",
      " - 2s - loss: 1052752.1887 - val_loss: 1125304.3335\n",
      "Epoch 38/500\n",
      " - 2s - loss: 1051453.2096 - val_loss: 1121403.5956\n",
      "Epoch 39/500\n",
      " - 2s - loss: 1050204.1035 - val_loss: 1117609.1653\n",
      "Epoch 40/500\n",
      " - 2s - loss: 1049003.3371 - val_loss: 1113917.5841\n",
      "Epoch 41/500\n",
      " - 2s - loss: 1047848.7180 - val_loss: 1110325.9044\n",
      "Epoch 42/500\n",
      " - 2s - loss: 1046738.3764 - val_loss: 1106830.8137\n",
      "Epoch 43/500\n",
      " - 2s - loss: 1045670.5595 - val_loss: 1103429.9411\n",
      "Epoch 44/500\n",
      " - 2s - loss: 1044643.6125 - val_loss: 1100119.8672\n",
      "Epoch 45/500\n",
      " - 2s - loss: 1043655.8017 - val_loss: 1096898.2602\n",
      "Epoch 46/500\n",
      " - 2s - loss: 1042705.6907 - val_loss: 1093762.5889\n",
      "Epoch 47/500\n",
      " - 2s - loss: 1041791.5501 - val_loss: 1090709.8504\n",
      "Epoch 48/500\n",
      " - 2s - loss: 1040912.1467 - val_loss: 1087737.8119\n",
      "Epoch 49/500\n",
      " - 2s - loss: 1040066.0474 - val_loss: 1084844.4700\n",
      "Epoch 50/500\n",
      " - 2s - loss: 1039251.9144 - val_loss: 1082026.8401\n",
      "Epoch 51/500\n",
      " - 2s - loss: 1038468.2447 - val_loss: 1079283.2103\n",
      "Epoch 52/500\n",
      " - 2s - loss: 1037714.1224 - val_loss: 1076611.4489\n",
      "Epoch 53/500\n",
      " - 2s - loss: 1036988.2283 - val_loss: 1074008.7446\n",
      "Epoch 54/500\n",
      " - 2s - loss: 1036289.5000 - val_loss: 1071474.0757\n",
      "Epoch 55/500\n",
      " - 2s - loss: 1035616.8187 - val_loss: 1069004.9471\n",
      "Epoch 56/500\n",
      " - 2s - loss: 1034969.2164 - val_loss: 1066599.9165\n",
      "Epoch 57/500\n",
      " - 2s - loss: 1034345.6000 - val_loss: 1064256.4621\n",
      "Epoch 58/500\n",
      " - 2s - loss: 1033745.0817 - val_loss: 1061973.1665\n",
      "Epoch 59/500\n",
      " - 2s - loss: 1033166.7434 - val_loss: 1059748.5589\n",
      "Epoch 60/500\n",
      " - 2s - loss: 1032609.7854 - val_loss: 1057580.5349\n",
      "Epoch 61/500\n",
      " - 2s - loss: 1032073.2664 - val_loss: 1055467.8816\n",
      "Epoch 62/500\n",
      " - 2s - loss: 1031556.3093 - val_loss: 1053409.1707\n",
      "Epoch 63/500\n",
      " - 2s - loss: 1031058.3757 - val_loss: 1051402.4772\n",
      "Epoch 64/500\n",
      " - 2s - loss: 1030578.6182 - val_loss: 1049446.5745\n",
      "Epoch 65/500\n",
      " - 2s - loss: 1030116.2791 - val_loss: 1047539.9369\n",
      "Epoch 66/500\n",
      " - 2s - loss: 1029670.6822 - val_loss: 1045680.9940\n",
      "Epoch 67/500\n",
      " - 2s - loss: 1029241.1879 - val_loss: 1043868.8648\n",
      "Epoch 68/500\n",
      " - 2s - loss: 1028827.3184 - val_loss: 1042102.1803\n",
      "Epoch 69/500\n",
      " - 2s - loss: 1028428.2061 - val_loss: 1040379.6052\n",
      "Epoch 70/500\n",
      " - 2s - loss: 1028043.2674 - val_loss: 1038699.6340\n",
      "Epoch 71/500\n",
      " - 2s - loss: 1027672.2218 - val_loss: 1037061.7344\n",
      "Epoch 72/500\n",
      " - 2s - loss: 1027314.4440 - val_loss: 1035463.7212\n",
      "Epoch 73/500\n",
      " - 2s - loss: 1026969.2684 - val_loss: 1033906.2013\n",
      "Epoch 74/500\n",
      " - 2s - loss: 1026636.5455 - val_loss: 1032386.6514\n",
      "Epoch 75/500\n",
      " - 2s - loss: 1026315.4896 - val_loss: 1030904.2157\n",
      "Epoch 76/500\n",
      " - 2s - loss: 1026005.6926 - val_loss: 1029458.1665\n",
      "Epoch 77/500\n",
      " - 2s - loss: 1025706.7802 - val_loss: 1028047.8522\n",
      "Epoch 78/500\n",
      " - 2s - loss: 1025418.4055 - val_loss: 1026671.9501\n",
      "Epoch 79/500\n",
      " - 2s - loss: 1025139.8980 - val_loss: 1025329.7163\n",
      "Epoch 80/500\n",
      " - 2s - loss: 1024871.2541 - val_loss: 1024019.7163\n",
      "Epoch 81/500\n",
      " - 2s - loss: 1024611.8017 - val_loss: 1022742.0913\n",
      "Epoch 82/500\n",
      " - 2s - loss: 1024361.4008 - val_loss: 1021494.8642\n",
      "Epoch 83/500\n",
      " - 2s - loss: 1024119.6943 - val_loss: 1020277.8480\n",
      "Epoch 84/500\n",
      " - 2s - loss: 1023886.2919 - val_loss: 1019090.3954\n",
      "Epoch 85/500\n",
      " - 2s - loss: 1023660.7904 - val_loss: 1017931.5907\n",
      "Epoch 86/500\n",
      " - 2s - loss: 1023442.9579 - val_loss: 1016800.8996\n",
      "Epoch 87/500\n",
      " - 2s - loss: 1023232.5743 - val_loss: 1015697.0763\n",
      "Epoch 88/500\n",
      " - 3s - loss: 1023029.5119 - val_loss: 1014619.7338\n",
      "Epoch 89/500\n",
      " - 3s - loss: 1022832.8780 - val_loss: 1013568.2620\n",
      "Epoch 90/500\n",
      " - 2s - loss: 1022643.2124 - val_loss: 1012541.8612\n",
      "Epoch 91/500\n",
      " - 3s - loss: 1022459.8131 - val_loss: 1011539.7175\n",
      "Epoch 92/500\n",
      " - 2s - loss: 1022282.5712 - val_loss: 1010561.4940\n",
      "Epoch 93/500\n",
      " - 3s - loss: 1022111.4016 - val_loss: 1009606.6100\n",
      "Epoch 94/500\n",
      " - 3s - loss: 1021945.7306 - val_loss: 1008674.5288\n",
      "Epoch 95/500\n",
      " - 3s - loss: 1021785.6698 - val_loss: 1007764.1839\n",
      "Epoch 96/500\n",
      " - 2s - loss: 1021630.6970 - val_loss: 1006875.4609\n",
      "Epoch 97/500\n",
      " - 2s - loss: 1021481.0209 - val_loss: 1006007.7362\n",
      "Epoch 98/500\n",
      " - 2s - loss: 1021336.0638 - val_loss: 1005160.2692\n",
      "Epoch 99/500\n",
      " - 3s - loss: 1021196.0612 - val_loss: 1004333.3395\n",
      "Epoch 100/500\n",
      " - 2s - loss: 1021060.4235 - val_loss: 1003524.9694\n",
      "Epoch 101/500\n",
      " - 2s - loss: 1020929.1599 - val_loss: 1002736.1310\n",
      "Epoch 102/500\n",
      " - 2s - loss: 1020802.4631 - val_loss: 1001965.5294\n",
      "Epoch 103/500\n",
      " - 2s - loss: 1020679.5202 - val_loss: 1001213.0787\n",
      "Epoch 104/500\n",
      " - 2s - loss: 1020560.5998 - val_loss: 1000478.0475\n",
      "Epoch 105/500\n",
      " - 2s - loss: 1020445.6083 - val_loss: 999760.2200\n",
      "Epoch 106/500\n",
      " - 2s - loss: 1020334.0732 - val_loss: 999059.0553\n",
      "Epoch 107/500\n",
      " - 2s - loss: 1020226.0554 - val_loss: 998374.2891\n",
      "Epoch 108/500\n",
      " - 2s - loss: 1020121.6121 - val_loss: 997705.2248\n",
      "Epoch 109/500\n",
      " - 2s - loss: 1020020.3424 - val_loss: 997051.8858\n",
      "Epoch 110/500\n",
      " - 2s - loss: 1019922.3602 - val_loss: 996413.0126\n",
      "Epoch 111/500\n",
      " - 2s - loss: 1019827.4226 - val_loss: 995789.4243\n",
      "Epoch 112/500\n",
      " - 2s - loss: 1019735.2448 - val_loss: 995179.9056\n",
      "Epoch 113/500\n",
      " - 2s - loss: 1019646.2425 - val_loss: 994584.7662\n",
      "Epoch 114/500\n",
      " - 2s - loss: 1019559.8032 - val_loss: 994003.4339\n",
      "Epoch 115/500\n",
      " - 2s - loss: 1019476.1166 - val_loss: 993435.0282\n",
      "Epoch 116/500\n",
      " - 2s - loss: 1019394.9233 - val_loss: 992880.3474\n",
      "Epoch 117/500\n",
      " - 2s - loss: 1019316.1889 - val_loss: 992337.8059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      " - 2s - loss: 1019239.8380 - val_loss: 991807.8510\n",
      "Epoch 119/500\n",
      " - 2s - loss: 1019165.8458 - val_loss: 991290.0403\n",
      "Epoch 120/500\n",
      " - 2s - loss: 1019094.1623 - val_loss: 990784.1328\n",
      "Epoch 121/500\n",
      " - 2s - loss: 1019024.5472 - val_loss: 990289.7945\n",
      "Epoch 122/500\n",
      " - 2s - loss: 1018957.1309 - val_loss: 989806.7716\n",
      "Epoch 123/500\n",
      " - 2s - loss: 1018891.5877 - val_loss: 989334.8504\n",
      "Epoch 124/500\n",
      " - 2s - loss: 1018828.1507 - val_loss: 988873.4297\n",
      "Epoch 125/500\n",
      " - 2s - loss: 1018766.4835 - val_loss: 988422.6791\n",
      "Epoch 126/500\n",
      " - 2s - loss: 1018706.6741 - val_loss: 987981.9026\n",
      "Epoch 127/500\n",
      " - 2s - loss: 1018648.5324 - val_loss: 987551.3618\n",
      "Epoch 128/500\n",
      " - 2s - loss: 1018592.4012 - val_loss: 987130.6220\n",
      "Epoch 129/500\n",
      " - 2s - loss: 1018537.6814 - val_loss: 986719.4141\n",
      "Epoch 130/500\n",
      " - 2s - loss: 1018484.7493 - val_loss: 986317.4531\n",
      "Epoch 131/500\n",
      " - 2s - loss: 1018433.0032 - val_loss: 985924.6677\n",
      "Epoch 132/500\n",
      " - 2s - loss: 1018382.7878 - val_loss: 985540.8576\n",
      "Epoch 133/500\n",
      " - 2s - loss: 1018334.2181 - val_loss: 985165.4934\n",
      "Epoch 134/500\n",
      " - 2s - loss: 1018287.0746 - val_loss: 984798.6094\n",
      "Epoch 135/500\n",
      " - 2s - loss: 1018241.2185 - val_loss: 984440.0427\n",
      "Epoch 136/500\n",
      " - 2s - loss: 1018196.7350 - val_loss: 984089.5925\n",
      "Epoch 137/500\n",
      " - 2s - loss: 1018153.3975 - val_loss: 983746.8167\n",
      "Epoch 138/500\n",
      " - 2s - loss: 1018111.3985 - val_loss: 983411.7242\n",
      "Epoch 139/500\n",
      " - 2s - loss: 1018070.3907 - val_loss: 983084.6508\n",
      "Epoch 140/500\n",
      " - 2s - loss: 1018030.7310 - val_loss: 982764.4303\n",
      "Epoch 141/500\n",
      " - 2s - loss: 1017991.8753 - val_loss: 982451.4480\n",
      "Epoch 142/500\n",
      " - 2s - loss: 1017954.4721 - val_loss: 982145.6193\n",
      "Epoch 143/500\n",
      " - 2s - loss: 1017918.0646 - val_loss: 981846.6451\n",
      "Epoch 144/500\n",
      " - 2s - loss: 1017882.4619 - val_loss: 981554.4252\n",
      "Epoch 145/500\n",
      " - 2s - loss: 1017848.0733 - val_loss: 981268.7533\n",
      "Epoch 146/500\n",
      " - 2s - loss: 1017814.4140 - val_loss: 980989.1178\n",
      "Epoch 147/500\n",
      " - 2s - loss: 1017781.7882 - val_loss: 980716.0532\n",
      "Epoch 148/500\n",
      " - 2s - loss: 1017750.0809 - val_loss: 980448.8032\n",
      "Epoch 149/500\n",
      " - 2s - loss: 1017719.2166 - val_loss: 980187.6268\n",
      "Epoch 150/500\n",
      " - 2s - loss: 1017689.0794 - val_loss: 979932.2572\n",
      "Epoch 151/500\n",
      " - 2s - loss: 1017659.8982 - val_loss: 979682.8080\n",
      "Epoch 152/500\n",
      " - 2s - loss: 1017631.3674 - val_loss: 979438.6656\n",
      "Epoch 153/500\n",
      " - 2s - loss: 1017603.8561 - val_loss: 979200.2446\n",
      "Epoch 154/500\n",
      " - 2s - loss: 1017576.8727 - val_loss: 978966.9919\n",
      "Epoch 155/500\n",
      " - 2s - loss: 1017550.8391 - val_loss: 978738.8401\n",
      "Epoch 156/500\n",
      " - 2s - loss: 1017525.1378 - val_loss: 978515.6313\n",
      "Epoch 157/500\n",
      " - 2s - loss: 1017500.4067 - val_loss: 978297.5880\n",
      "Epoch 158/500\n",
      " - 2s - loss: 1017476.0518 - val_loss: 978084.1602\n",
      "Epoch 159/500\n",
      " - 2s - loss: 1017452.4669 - val_loss: 977875.6941\n",
      "Epoch 160/500\n",
      " - 2s - loss: 1017429.7077 - val_loss: 977671.8768\n",
      "Epoch 161/500\n",
      " - 2s - loss: 1017407.2940 - val_loss: 977472.3380\n",
      "Epoch 162/500\n",
      " - 2s - loss: 1017385.6536 - val_loss: 977277.6160\n",
      "Epoch 163/500\n",
      " - 2s - loss: 1017364.5614 - val_loss: 977086.9132\n",
      "Epoch 164/500\n",
      " - 2s - loss: 1017344.0498 - val_loss: 976900.6854\n",
      "Epoch 165/500\n",
      " - 2s - loss: 1017323.8098 - val_loss: 976718.2581\n",
      "Epoch 166/500\n",
      " - 2s - loss: 1017304.3201 - val_loss: 976540.0634\n",
      "Epoch 167/500\n",
      " - 2s - loss: 1017285.1491 - val_loss: 976365.7719\n",
      "Epoch 168/500\n",
      " - 2s - loss: 1017266.6545 - val_loss: 976195.3296\n",
      "Epoch 169/500\n",
      " - 2s - loss: 1017248.6318 - val_loss: 976028.5120\n",
      "Epoch 170/500\n",
      " - 2s - loss: 1017231.0774 - val_loss: 975865.5826\n",
      "Epoch 171/500\n",
      " - 2s - loss: 1017213.9195 - val_loss: 975706.1523\n",
      "Epoch 172/500\n",
      " - 2s - loss: 1017197.0609 - val_loss: 975550.2834\n",
      "Epoch 173/500\n",
      " - 2s - loss: 1017180.7909 - val_loss: 975397.9078\n",
      "Epoch 174/500\n",
      " - 2s - loss: 1017164.7809 - val_loss: 975248.8245\n",
      "Epoch 175/500\n",
      " - 2s - loss: 1017149.3908 - val_loss: 975102.6668\n",
      "Epoch 176/500\n",
      " - 2s - loss: 1017134.1950 - val_loss: 974960.0919\n",
      "Epoch 177/500\n",
      " - 2s - loss: 1017119.5564 - val_loss: 974820.5634\n",
      "Epoch 178/500\n",
      " - 2s - loss: 1017105.1433 - val_loss: 974684.2882\n",
      "Epoch 179/500\n",
      " - 2s - loss: 1017091.2500 - val_loss: 974550.9751\n",
      "Epoch 180/500\n",
      " - 2s - loss: 1017077.5024 - val_loss: 974420.1478\n",
      "Epoch 181/500\n",
      " - 2s - loss: 1017064.1570 - val_loss: 974292.6091\n",
      "Epoch 182/500\n",
      " - 2s - loss: 1017051.1972 - val_loss: 974167.7151\n",
      "Epoch 183/500\n",
      " - 2s - loss: 1017038.5444 - val_loss: 974045.8299\n",
      "Epoch 184/500\n",
      " - 2s - loss: 1017026.0419 - val_loss: 973926.4736\n",
      "Epoch 185/500\n",
      " - 2s - loss: 1017014.1633 - val_loss: 973809.8468\n",
      "Epoch 186/500\n",
      " - 2s - loss: 1017002.4093 - val_loss: 973695.4555\n",
      "Epoch 187/500\n",
      " - 3s - loss: 1016990.8416 - val_loss: 973583.7428\n",
      "Epoch 188/500\n",
      " - 3s - loss: 1016979.6469 - val_loss: 973474.5303\n",
      "Epoch 189/500\n",
      " - 2s - loss: 1016968.7652 - val_loss: 973367.5995\n",
      "Epoch 190/500\n",
      " - 3s - loss: 1016958.1991 - val_loss: 973263.1427\n",
      "Epoch 191/500\n",
      " - 3s - loss: 1016947.8826 - val_loss: 973161.0655\n",
      "Epoch 192/500\n",
      " - 2s - loss: 1016937.7462 - val_loss: 973061.1271\n",
      "Epoch 193/500\n",
      " - 2s - loss: 1016927.8890 - val_loss: 972963.6529\n",
      "Epoch 194/500\n",
      " - 2s - loss: 1016918.2539 - val_loss: 972867.9483\n",
      "Epoch 195/500\n",
      " - 2s - loss: 1016908.8304 - val_loss: 972774.5126\n",
      "Epoch 196/500\n",
      " - 2s - loss: 1016899.7108 - val_loss: 972682.9901\n",
      "Epoch 197/500\n",
      " - 2s - loss: 1016890.7029 - val_loss: 972593.5838\n",
      "Epoch 198/500\n",
      " - 2s - loss: 1016881.9016 - val_loss: 972505.9492\n",
      "Epoch 199/500\n",
      " - 2s - loss: 1016873.5197 - val_loss: 972420.1559\n",
      "Epoch 200/500\n",
      " - 3s - loss: 1016865.1005 - val_loss: 972336.6917\n",
      "Epoch 201/500\n",
      " - 2s - loss: 1016856.8871 - val_loss: 972254.5264\n",
      "Epoch 202/500\n",
      " - 2s - loss: 1016848.9476 - val_loss: 972174.5427\n",
      "Epoch 203/500\n",
      " - 2s - loss: 1016841.1135 - val_loss: 972096.3341\n",
      "Epoch 204/500\n",
      " - 3s - loss: 1016833.6862 - val_loss: 972019.7181\n",
      "Epoch 205/500\n",
      " - 3s - loss: 1016826.3871 - val_loss: 971944.5820\n",
      "Epoch 206/500\n",
      " - 2s - loss: 1016818.9415 - val_loss: 971871.5036\n",
      "Epoch 207/500\n",
      " - 2s - loss: 1016812.0627 - val_loss: 971799.2692\n",
      "Epoch 208/500\n",
      " - 2s - loss: 1016805.1658 - val_loss: 971729.3254\n",
      "Epoch 209/500\n",
      " - 2s - loss: 1016798.2751 - val_loss: 971660.5736\n",
      "Epoch 210/500\n",
      " - 2s - loss: 1016791.8171 - val_loss: 971593.5255\n",
      "Epoch 211/500\n",
      " - 2s - loss: 1016785.2570 - val_loss: 971527.7900\n",
      "Epoch 212/500\n",
      " - 3s - loss: 1016779.2356 - val_loss: 971463.6499\n",
      "Epoch 213/500\n",
      " - 2s - loss: 1016773.1440 - val_loss: 971400.9032\n",
      "Epoch 214/500\n",
      " - 2s - loss: 1016767.0959 - val_loss: 971339.3717\n",
      "Epoch 215/500\n",
      " - 2s - loss: 1016761.3162 - val_loss: 971279.5409\n",
      "Epoch 216/500\n",
      " - 2s - loss: 1016755.5270 - val_loss: 971220.5977\n",
      "Epoch 217/500\n",
      " - 2s - loss: 1016749.8590 - val_loss: 971162.9522\n",
      "Epoch 218/500\n",
      " - 2s - loss: 1016744.6829 - val_loss: 971106.8591\n",
      "Epoch 219/500\n",
      " - 2s - loss: 1016739.3647 - val_loss: 971051.7644\n",
      "Epoch 220/500\n",
      " - 2s - loss: 1016733.9709 - val_loss: 970997.6178\n",
      "Epoch 221/500\n",
      " - 2s - loss: 1016729.0020 - val_loss: 970944.9754\n",
      "Epoch 222/500\n",
      " - 2s - loss: 1016724.0000 - val_loss: 970893.4811\n",
      "Epoch 223/500\n",
      " - 2s - loss: 1016719.1512 - val_loss: 970843.0904\n",
      "Epoch 224/500\n",
      " - 2s - loss: 1016714.5312 - val_loss: 970793.8684\n",
      "Epoch 225/500\n",
      " - 2s - loss: 1016709.9078 - val_loss: 970745.4826\n",
      "Epoch 226/500\n",
      " - 2s - loss: 1016705.3796 - val_loss: 970698.2001\n",
      "Epoch 227/500\n",
      " - 2s - loss: 1016701.0202 - val_loss: 970652.2263\n",
      "Epoch 228/500\n",
      " - 2s - loss: 1016696.6938 - val_loss: 970607.1887\n",
      "Epoch 229/500\n",
      " - 2s - loss: 1016692.4983 - val_loss: 970563.0715\n",
      "Epoch 230/500\n",
      " - 2s - loss: 1016688.4994 - val_loss: 970520.0105\n",
      "Epoch 231/500\n",
      " - 2s - loss: 1016684.3658 - val_loss: 970477.8648\n",
      "Epoch 232/500\n",
      " - 2s - loss: 1016680.4443 - val_loss: 970436.3987\n",
      "Epoch 233/500\n",
      " - 2s - loss: 1016676.6968 - val_loss: 970396.2951\n",
      "Epoch 234/500\n",
      " - 2s - loss: 1016672.9315 - val_loss: 970356.7518\n",
      "Epoch 235/500\n",
      " - 2s - loss: 1016669.0652 - val_loss: 970317.7927\n",
      "Epoch 236/500\n",
      " - 2s - loss: 1016665.6763 - val_loss: 970280.0956\n",
      "Epoch 237/500\n",
      " - 2s - loss: 1016662.2296 - val_loss: 970243.1010\n",
      "Epoch 238/500\n",
      " - 2s - loss: 1016658.7515 - val_loss: 970206.7377\n",
      "Epoch 239/500\n",
      " - 2s - loss: 1016655.3795 - val_loss: 970171.6325\n",
      "Epoch 240/500\n",
      " - 2s - loss: 1016652.3692 - val_loss: 970136.6596\n",
      "Epoch 241/500\n",
      " - 2s - loss: 1016649.1648 - val_loss: 970102.7233\n",
      "Epoch 242/500\n",
      " - 2s - loss: 1016645.7983 - val_loss: 970069.6848\n",
      "Epoch 243/500\n",
      " - 2s - loss: 1016642.9163 - val_loss: 970037.4390\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 1016639.7823 - val_loss: 970005.6752\n",
      "Epoch 245/500\n",
      " - 2s - loss: 1016636.9479 - val_loss: 969974.5739\n",
      "Epoch 246/500\n",
      " - 2s - loss: 1016634.1335 - val_loss: 969944.4531\n",
      "Epoch 247/500\n",
      " - 2s - loss: 1016631.5333 - val_loss: 969915.0048\n",
      "Epoch 248/500\n",
      " - 2s - loss: 1016628.7079 - val_loss: 969885.5856\n",
      "Epoch 249/500\n",
      " - 2s - loss: 1016625.9776 - val_loss: 969857.1352\n",
      "Epoch 250/500\n",
      " - 2s - loss: 1016623.4040 - val_loss: 969829.4282\n",
      "Epoch 251/500\n",
      " - 3s - loss: 1016620.9189 - val_loss: 969802.4050\n",
      "Epoch 252/500\n",
      " - 3s - loss: 1016618.4918 - val_loss: 969775.8053\n",
      "Epoch 253/500\n",
      " - 3s - loss: 1016616.0072 - val_loss: 969749.4477\n",
      "Epoch 254/500\n",
      " - 2s - loss: 1016613.5972 - val_loss: 969723.9408\n",
      "Epoch 255/500\n",
      " - 2s - loss: 1016611.2323 - val_loss: 969698.9102\n",
      "Epoch 256/500\n",
      " - 2s - loss: 1016608.9054 - val_loss: 969674.5288\n",
      "Epoch 257/500\n",
      " - 2s - loss: 1016606.7854 - val_loss: 969650.6001\n",
      "Epoch 258/500\n",
      " - 2s - loss: 1016604.5835 - val_loss: 969627.2188\n",
      "Epoch 259/500\n",
      " - 2s - loss: 1016602.5330 - val_loss: 969604.5060\n",
      "Epoch 260/500\n",
      " - 2s - loss: 1016600.4396 - val_loss: 969582.2308\n",
      "Epoch 261/500\n",
      " - 2s - loss: 1016598.4181 - val_loss: 969560.3341\n",
      "Epoch 262/500\n",
      " - 2s - loss: 1016596.5071 - val_loss: 969538.8425\n",
      "Epoch 263/500\n",
      " - 2s - loss: 1016594.5022 - val_loss: 969517.5691\n",
      "Epoch 264/500\n",
      " - 2s - loss: 1016592.5573 - val_loss: 969497.1058\n",
      "Epoch 265/500\n",
      " - 2s - loss: 1016590.6273 - val_loss: 969477.2894\n",
      "Epoch 266/500\n",
      " - 2s - loss: 1016588.8839 - val_loss: 969457.4976\n",
      "Epoch 267/500\n",
      " - 2s - loss: 1016587.2156 - val_loss: 969438.2479\n",
      "Epoch 268/500\n",
      " - 2s - loss: 1016585.5080 - val_loss: 969419.4399\n",
      "Epoch 269/500\n",
      " - 2s - loss: 1016583.6048 - val_loss: 969401.0922\n",
      "Epoch 270/500\n",
      " - 2s - loss: 1016581.9654 - val_loss: 969382.9841\n",
      "Epoch 271/500\n",
      " - 2s - loss: 1016580.3284 - val_loss: 969365.2443\n",
      "Epoch 272/500\n",
      " - 2s - loss: 1016578.8959 - val_loss: 969348.2305\n",
      "Epoch 273/500\n",
      " - 2s - loss: 1016577.2851 - val_loss: 969331.2948\n",
      "Epoch 274/500\n",
      " - 2s - loss: 1016575.7695 - val_loss: 969314.9766\n",
      "Epoch 275/500\n",
      " - 2s - loss: 1016574.4313 - val_loss: 969298.8450\n",
      "Epoch 276/500\n",
      " - 2s - loss: 1016572.8570 - val_loss: 969283.4297\n",
      "Epoch 277/500\n",
      " - 2s - loss: 1016571.3465 - val_loss: 969267.8185\n",
      "Epoch 278/500\n",
      " - 2s - loss: 1016569.9598 - val_loss: 969252.8416\n",
      "Epoch 279/500\n",
      " - 2s - loss: 1016568.7018 - val_loss: 969237.8846\n",
      "Epoch 280/500\n",
      " - 2s - loss: 1016567.3052 - val_loss: 969223.7374\n",
      "Epoch 281/500\n",
      " - 2s - loss: 1016566.1138 - val_loss: 969209.3951\n",
      "Epoch 282/500\n",
      " - 2s - loss: 1016564.7324 - val_loss: 969195.8308\n",
      "Epoch 283/500\n",
      " - 2s - loss: 1016563.4844 - val_loss: 969182.3212\n",
      "Epoch 284/500\n",
      " - 2s - loss: 1016562.4771 - val_loss: 969168.8573\n",
      "Epoch 285/500\n",
      " - 2s - loss: 1016561.1344 - val_loss: 969156.0258\n",
      "Epoch 286/500\n",
      " - 2s - loss: 1016559.9408 - val_loss: 969143.5352\n",
      "Epoch 287/500\n",
      " - 2s - loss: 1016558.8324 - val_loss: 969130.8182\n",
      "Epoch 288/500\n",
      " - 2s - loss: 1016557.7747 - val_loss: 969118.8164\n",
      "Epoch 289/500\n",
      " - 2s - loss: 1016556.7762 - val_loss: 969106.8263\n",
      "Epoch 290/500\n",
      " - 2s - loss: 1016555.5606 - val_loss: 969095.3603\n",
      "Epoch 291/500\n",
      " - 2s - loss: 1016554.6564 - val_loss: 969083.8843\n",
      "Epoch 292/500\n",
      " - 2s - loss: 1016553.4558 - val_loss: 969073.0559\n",
      "Epoch 293/500\n",
      " - 2s - loss: 1016552.6154 - val_loss: 969062.2227\n",
      "Epoch 294/500\n",
      " - 2s - loss: 1016551.6398 - val_loss: 969051.5643\n",
      "Epoch 295/500\n",
      " - 2s - loss: 1016550.6033 - val_loss: 969041.3981\n",
      "Epoch 296/500\n",
      " - 2s - loss: 1016549.8244 - val_loss: 969031.2188\n",
      "Epoch 297/500\n",
      " - 2s - loss: 1016548.7444 - val_loss: 969021.3149\n",
      "Epoch 298/500\n",
      " - 2s - loss: 1016547.8903 - val_loss: 969011.6058\n",
      "Epoch 299/500\n",
      " - 2s - loss: 1016547.1530 - val_loss: 969001.9910\n",
      "Epoch 300/500\n",
      " - 2s - loss: 1016546.1706 - val_loss: 968992.8422\n",
      "Epoch 301/500\n",
      " - 2s - loss: 1016545.5052 - val_loss: 968983.8624\n",
      "Epoch 302/500\n",
      " - 2s - loss: 1016544.5886 - val_loss: 968974.8398\n",
      "Epoch 303/500\n",
      " - 2s - loss: 1016543.8638 - val_loss: 968966.1070\n",
      "Epoch 304/500\n",
      " - 2s - loss: 1016543.0568 - val_loss: 968957.7707\n",
      "Epoch 305/500\n",
      " - 2s - loss: 1016542.2090 - val_loss: 968949.5216\n",
      "Epoch 306/500\n",
      " - 2s - loss: 1016541.5680 - val_loss: 968941.2485\n",
      "Epoch 307/500\n",
      " - 2s - loss: 1016540.8227 - val_loss: 968933.0273\n",
      "Epoch 308/500\n",
      " - 2s - loss: 1016540.0202 - val_loss: 968925.1890\n",
      "Epoch 309/500\n",
      " - 2s - loss: 1016539.3708 - val_loss: 968917.7659\n",
      "Epoch 310/500\n",
      " - 2s - loss: 1016538.8549 - val_loss: 968910.1532\n",
      "Epoch 311/500\n",
      " - 2s - loss: 1016537.9996 - val_loss: 968902.9420\n",
      "Epoch 312/500\n",
      " - 2s - loss: 1016537.4158 - val_loss: 968895.8483\n",
      "Epoch 313/500\n",
      " - 2s - loss: 1016536.7175 - val_loss: 968888.8269\n",
      "Epoch 314/500\n",
      " - 2s - loss: 1016536.1362 - val_loss: 968881.9435\n",
      "Epoch 315/500\n",
      " - 2s - loss: 1016535.5691 - val_loss: 968875.0938\n",
      "Epoch 316/500\n",
      " - 2s - loss: 1016535.0030 - val_loss: 968868.7506\n",
      "Epoch 317/500\n",
      " - 2s - loss: 1016534.4683 - val_loss: 968862.1749\n",
      "Epoch 318/500\n",
      " - 3s - loss: 1016533.7956 - val_loss: 968855.9958\n",
      "Epoch 319/500\n",
      " - 2s - loss: 1016533.2672 - val_loss: 968850.0063\n",
      "Epoch 320/500\n",
      " - 2s - loss: 1016532.7603 - val_loss: 968844.1608\n",
      "Epoch 321/500\n",
      " - 2s - loss: 1016532.1701 - val_loss: 968838.2133\n",
      "Epoch 322/500\n",
      " - 2s - loss: 1016531.6459 - val_loss: 968832.7251\n",
      "Epoch 323/500\n",
      " - 2s - loss: 1016531.1512 - val_loss: 968827.0574\n",
      "Epoch 324/500\n",
      " - 2s - loss: 1016530.6613 - val_loss: 968821.3786\n",
      "Epoch 325/500\n",
      " - 2s - loss: 1016530.1512 - val_loss: 968816.0601\n",
      "Epoch 326/500\n",
      " - 2s - loss: 1016529.7044 - val_loss: 968810.9994\n",
      "Epoch 327/500\n",
      " - 3s - loss: 1016529.1757 - val_loss: 968805.6508\n",
      "Epoch 328/500\n",
      " - 2s - loss: 1016528.8618 - val_loss: 968800.5526\n",
      "Epoch 329/500\n",
      " - 2s - loss: 1016528.3460 - val_loss: 968795.7091\n",
      "Epoch 330/500\n",
      " - 3s - loss: 1016527.9015 - val_loss: 968791.0096\n",
      "Epoch 331/500\n",
      " - 2s - loss: 1016527.4442 - val_loss: 968786.3687\n",
      "Epoch 332/500\n",
      " - 2s - loss: 1016527.0352 - val_loss: 968781.6995\n",
      "Epoch 333/500\n",
      " - 2s - loss: 1016526.6434 - val_loss: 968777.2103\n",
      "Epoch 334/500\n",
      " - 3s - loss: 1016526.3396 - val_loss: 968772.7031\n",
      "Epoch 335/500\n",
      " - 3s - loss: 1016526.0150 - val_loss: 968768.4282\n",
      "Epoch 336/500\n",
      " - 3s - loss: 1016525.4759 - val_loss: 968764.0763\n",
      "Epoch 337/500\n",
      " - 2s - loss: 1016524.9537 - val_loss: 968759.8591\n",
      "Epoch 338/500\n",
      " - 3s - loss: 1016524.6137 - val_loss: 968755.5150\n",
      "Epoch 339/500\n",
      " - 3s - loss: 1016524.3781 - val_loss: 968751.9216\n",
      "Epoch 340/500\n",
      " - 3s - loss: 1016524.0822 - val_loss: 968748.1124\n",
      "Epoch 341/500\n",
      " - 3s - loss: 1016523.6052 - val_loss: 968743.8906\n",
      "Epoch 342/500\n",
      " - 3s - loss: 1016523.3413 - val_loss: 968740.1241\n",
      "Epoch 343/500\n",
      " - 2s - loss: 1016523.0319 - val_loss: 968736.4775\n",
      "Epoch 344/500\n",
      " - 2s - loss: 1016522.8108 - val_loss: 968732.9706\n",
      "Epoch 345/500\n",
      " - 2s - loss: 1016522.3750 - val_loss: 968729.5808\n",
      "Epoch 346/500\n",
      " - 2s - loss: 1016521.9529 - val_loss: 968726.5198\n",
      "Epoch 347/500\n",
      " - 2s - loss: 1016521.6266 - val_loss: 968723.2641\n",
      "Epoch 348/500\n",
      " - 2s - loss: 1016521.3242 - val_loss: 968720.0210\n",
      "Epoch 349/500\n",
      " - 3s - loss: 1016521.0501 - val_loss: 968716.7758\n",
      "Epoch 350/500\n",
      " - 3s - loss: 1016520.7783 - val_loss: 968713.5394\n",
      "Epoch 351/500\n",
      " - 2s - loss: 1016520.6871 - val_loss: 968710.3314\n",
      "Epoch 352/500\n",
      " - 2s - loss: 1016520.4097 - val_loss: 968707.5030\n",
      "Epoch 353/500\n",
      " - 2s - loss: 1016520.1908 - val_loss: 968704.3774\n",
      "Epoch 354/500\n",
      " - 2s - loss: 1016519.8583 - val_loss: 968701.7653\n",
      "Epoch 355/500\n",
      " - 2s - loss: 1016519.5346 - val_loss: 968698.9087\n",
      "Epoch 356/500\n",
      " - 2s - loss: 1016519.2966 - val_loss: 968696.3450\n",
      "Epoch 357/500\n",
      " - 2s - loss: 1016518.9433 - val_loss: 968693.7239\n",
      "Epoch 358/500\n",
      " - 2s - loss: 1016518.9374 - val_loss: 968691.0871\n",
      "Epoch 359/500\n",
      " - 2s - loss: 1016518.7884 - val_loss: 968688.7404\n",
      "Epoch 360/500\n",
      " - 2s - loss: 1016518.5185 - val_loss: 968686.4117\n",
      "Epoch 361/500\n",
      " - 2s - loss: 1016518.1667 - val_loss: 968683.8489\n",
      "Epoch 362/500\n",
      " - 2s - loss: 1016517.9306 - val_loss: 968681.3083\n",
      "Epoch 363/500\n",
      " - 2s - loss: 1016517.7739 - val_loss: 968678.8215\n",
      "Epoch 364/500\n",
      " - 2s - loss: 1016517.5746 - val_loss: 968676.5424\n",
      "Epoch 365/500\n",
      " - 2s - loss: 1016517.4341 - val_loss: 968674.3783\n",
      "Epoch 366/500\n",
      " - 3s - loss: 1016517.1771 - val_loss: 968672.1569\n",
      "Epoch 367/500\n",
      " - 2s - loss: 1016516.8834 - val_loss: 968670.0057\n",
      "Epoch 368/500\n",
      " - 2s - loss: 1016516.6929 - val_loss: 968668.1211\n",
      "Epoch 369/500\n",
      " - 3s - loss: 1016516.4546 - val_loss: 968666.2392\n",
      "Epoch 370/500\n",
      " - 2s - loss: 1016516.2849 - val_loss: 968664.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500\n",
      " - 2s - loss: 1016516.1781 - val_loss: 968662.4120\n",
      "Epoch 372/500\n",
      " - 2s - loss: 1016516.2023 - val_loss: 968660.8233\n",
      "Epoch 373/500\n",
      " - 2s - loss: 1016516.0082 - val_loss: 968659.1890\n",
      "Epoch 374/500\n",
      " - 2s - loss: 1016515.9314 - val_loss: 968657.3413\n",
      "Epoch 375/500\n",
      " - 2s - loss: 1016515.8109 - val_loss: 968655.5135\n",
      "Epoch 376/500\n",
      " - 2s - loss: 1016515.5690 - val_loss: 968653.6914\n",
      "Epoch 377/500\n",
      " - 2s - loss: 1016515.4156 - val_loss: 968651.9053\n",
      "Epoch 378/500\n",
      " - 2s - loss: 1016515.2498 - val_loss: 968650.0595\n",
      "Epoch 379/500\n",
      " - 2s - loss: 1016515.0878 - val_loss: 968648.6650\n",
      "Epoch 380/500\n",
      " - 2s - loss: 1016514.9788 - val_loss: 968646.8359\n",
      "Epoch 381/500\n",
      " - 2s - loss: 1016514.8126 - val_loss: 968645.3657\n",
      "Epoch 382/500\n",
      " - 3s - loss: 1016514.6026 - val_loss: 968643.8314\n",
      "Epoch 383/500\n",
      " - 3s - loss: 1016514.4056 - val_loss: 968642.4883\n",
      "Epoch 384/500\n",
      " - 2s - loss: 1016514.3404 - val_loss: 968641.0075\n",
      "Epoch 385/500\n",
      " - 2s - loss: 1016514.2145 - val_loss: 968639.7386\n",
      "Epoch 386/500\n",
      " - 2s - loss: 1016513.9660 - val_loss: 968638.3918\n",
      "Epoch 387/500\n",
      " - 2s - loss: 1016513.8857 - val_loss: 968637.0358\n",
      "Epoch 388/500\n",
      " - 2s - loss: 1016513.7674 - val_loss: 968635.5571\n",
      "Epoch 389/500\n",
      " - 2s - loss: 1016513.5904 - val_loss: 968634.3759\n",
      "Epoch 390/500\n",
      " - 2s - loss: 1016513.2722 - val_loss: 968632.8026\n",
      "Epoch 391/500\n",
      " - 2s - loss: 1016513.2498 - val_loss: 968631.5754\n",
      "Epoch 392/500\n",
      " - 2s - loss: 1016513.2306 - val_loss: 968630.1487\n",
      "Epoch 393/500\n",
      " - 2s - loss: 1016513.2080 - val_loss: 968628.5622\n",
      "Epoch 394/500\n",
      " - 2s - loss: 1016513.1044 - val_loss: 968627.4808\n",
      "Epoch 395/500\n",
      " - 2s - loss: 1016513.0344 - val_loss: 968625.8678\n",
      "Epoch 396/500\n",
      " - 2s - loss: 1016513.0339 - val_loss: 968624.5793\n",
      "Epoch 397/500\n",
      " - 2s - loss: 1016512.8477 - val_loss: 968623.2909\n",
      "Epoch 398/500\n",
      " - 2s - loss: 1016512.5884 - val_loss: 968622.3945\n",
      "Epoch 399/500\n",
      " - 2s - loss: 1016512.5830 - val_loss: 968621.1490\n",
      "Epoch 400/500\n",
      " - 2s - loss: 1016512.4973 - val_loss: 968619.9618\n",
      "Epoch 401/500\n",
      " - 2s - loss: 1016512.3377 - val_loss: 968618.7599\n",
      "Epoch 402/500\n",
      " - 2s - loss: 1016512.2262 - val_loss: 968617.8561\n",
      "Epoch 403/500\n",
      " - 3s - loss: 1016512.1256 - val_loss: 968616.7812\n",
      "Epoch 404/500\n",
      " - 2s - loss: 1016512.1156 - val_loss: 968615.6902\n",
      "Epoch 405/500\n",
      " - 2s - loss: 1016512.0012 - val_loss: 968614.8537\n",
      "Epoch 406/500\n",
      " - 2s - loss: 1016511.9840 - val_loss: 968613.9020\n",
      "Epoch 407/500\n",
      " - 2s - loss: 1016512.0546 - val_loss: 968613.1520\n",
      "Epoch 408/500\n",
      " - 2s - loss: 1016511.9135 - val_loss: 968612.2647\n",
      "Epoch 409/500\n",
      " - 2s - loss: 1016511.7572 - val_loss: 968611.7070\n",
      "Epoch 410/500\n",
      " - 2s - loss: 1016511.5590 - val_loss: 968611.0006\n",
      "Epoch 411/500\n",
      " - 2s - loss: 1016511.4713 - val_loss: 968610.1007\n",
      "Epoch 412/500\n",
      " - 2s - loss: 1016511.4694 - val_loss: 968609.5198\n",
      "Epoch 413/500\n",
      " - 2s - loss: 1016511.3907 - val_loss: 968608.7888\n",
      "Epoch 414/500\n",
      " - 2s - loss: 1016511.3491 - val_loss: 968607.9913\n",
      "Epoch 415/500\n",
      " - 2s - loss: 1016511.3014 - val_loss: 968607.3780\n",
      "Epoch 416/500\n",
      " - 2s - loss: 1016511.2202 - val_loss: 968606.5922\n",
      "Epoch 417/500\n",
      " - 2s - loss: 1016511.1548 - val_loss: 968605.8924\n",
      "Epoch 418/500\n",
      " - 2s - loss: 1016511.0908 - val_loss: 968604.9694\n",
      "Epoch 419/500\n",
      " - 2s - loss: 1016511.0614 - val_loss: 968604.0706\n",
      "Epoch 420/500\n",
      " - 2s - loss: 1016510.8868 - val_loss: 968603.1665\n",
      "Epoch 421/500\n",
      " - 2s - loss: 1016510.8474 - val_loss: 968602.5222\n",
      "Epoch 422/500\n",
      " - 2s - loss: 1016510.8268 - val_loss: 968601.8924\n",
      "Epoch 423/500\n",
      " - 2s - loss: 1016510.7191 - val_loss: 968601.1836\n",
      "Epoch 424/500\n",
      " - 2s - loss: 1016510.6607 - val_loss: 968600.6259\n",
      "Epoch 425/500\n",
      " - 2s - loss: 1016510.5347 - val_loss: 968599.7266\n",
      "Epoch 426/500\n",
      " - 3s - loss: 1016510.4504 - val_loss: 968599.2746\n",
      "Epoch 427/500\n",
      " - 2s - loss: 1016510.3310 - val_loss: 968598.8035\n",
      "Epoch 428/500\n",
      " - 2s - loss: 1016510.3553 - val_loss: 968598.0971\n",
      "Epoch 429/500\n",
      " - 2s - loss: 1016510.2095 - val_loss: 968597.7317\n",
      "Epoch 430/500\n",
      " - 2s - loss: 1016510.2087 - val_loss: 968597.1043\n",
      "Epoch 431/500\n",
      " - 2s - loss: 1016510.1514 - val_loss: 968596.8254\n",
      "Epoch 432/500\n",
      " - 2s - loss: 1016510.2129 - val_loss: 968596.0947\n",
      "Epoch 433/500\n",
      " - 2s - loss: 1016510.1352 - val_loss: 968595.9459\n",
      "Epoch 434/500\n",
      " - 2s - loss: 1016510.0769 - val_loss: 968595.3080\n",
      "Epoch 435/500\n",
      " - 2s - loss: 1016510.1423 - val_loss: 968594.6475\n",
      "Epoch 436/500\n",
      " - 2s - loss: 1016510.0119 - val_loss: 968594.2822\n",
      "Epoch 437/500\n",
      " - 2s - loss: 1016510.0191 - val_loss: 968593.7245\n",
      "Epoch 438/500\n",
      " - 2s - loss: 1016509.9574 - val_loss: 968593.2668\n",
      "Epoch 439/500\n",
      " - 3s - loss: 1016509.9452 - val_loss: 968592.6334\n",
      "Epoch 440/500\n",
      " - 3s - loss: 1016509.8631 - val_loss: 968592.1815\n",
      "Epoch 441/500\n",
      " - 3s - loss: 1016509.8590 - val_loss: 968591.6130\n",
      "Epoch 442/500\n",
      " - 3s - loss: 1016509.7382 - val_loss: 968591.1526\n",
      "Epoch 443/500\n",
      " - 3s - loss: 1016509.7586 - val_loss: 968590.6406\n",
      "Epoch 444/500\n",
      " - 3s - loss: 1016509.8018 - val_loss: 968590.2296\n",
      "Epoch 445/500\n",
      " - 2s - loss: 1016509.8026 - val_loss: 968589.5075\n",
      "Epoch 446/500\n",
      " - 3s - loss: 1016509.7624 - val_loss: 968589.0733\n",
      "Epoch 447/500\n",
      " - 2s - loss: 1016509.7130 - val_loss: 968588.6022\n",
      "Epoch 448/500\n",
      " - 2s - loss: 1016509.6279 - val_loss: 968588.1322\n",
      "Epoch 449/500\n",
      " - 2s - loss: 1016509.6412 - val_loss: 968587.6836\n",
      "Epoch 450/500\n",
      " - 2s - loss: 1016509.6000 - val_loss: 968587.5252\n",
      "Epoch 451/500\n",
      " - 2s - loss: 1016509.5572 - val_loss: 968586.9675\n",
      "Epoch 452/500\n",
      " - 2s - loss: 1016509.5483 - val_loss: 968586.5346\n",
      "Epoch 453/500\n",
      " - 2s - loss: 1016509.4442 - val_loss: 968586.2407\n",
      "Epoch 454/500\n",
      " - 2s - loss: 1016509.4324 - val_loss: 968585.6400\n",
      "Epoch 455/500\n",
      " - 2s - loss: 1016509.3899 - val_loss: 968585.2828\n",
      "Epoch 456/500\n",
      " - 2s - loss: 1016509.3339 - val_loss: 968584.8116\n",
      "Epoch 457/500\n",
      " - 2s - loss: 1016509.2897 - val_loss: 968584.3017\n",
      "Epoch 458/500\n",
      " - 2s - loss: 1016509.2004 - val_loss: 968583.8945\n",
      "Epoch 459/500\n",
      " - 2s - loss: 1016509.2366 - val_loss: 968583.4651\n",
      "Epoch 460/500\n",
      " - 2s - loss: 1016509.2045 - val_loss: 968583.2290\n",
      "Epoch 461/500\n",
      " - 2s - loss: 1016509.1448 - val_loss: 968582.8404\n",
      "Epoch 462/500\n",
      " - 2s - loss: 1016509.0933 - val_loss: 968582.4751\n",
      "Epoch 463/500\n",
      " - 2s - loss: 1016509.0602 - val_loss: 968582.3257\n",
      "Epoch 464/500\n",
      " - 2s - loss: 1016508.9778 - val_loss: 968581.9213\n",
      "Epoch 465/500\n",
      " - 2s - loss: 1016508.9367 - val_loss: 968581.5941\n",
      "Epoch 466/500\n",
      " - 2s - loss: 1016508.8884 - val_loss: 968581.4026\n",
      "Epoch 467/500\n",
      " - 2s - loss: 1016508.7914 - val_loss: 968581.0180\n",
      "Epoch 468/500\n",
      " - 2s - loss: 1016508.8277 - val_loss: 968580.6941\n",
      "Epoch 469/500\n",
      " - 2s - loss: 1016508.7519 - val_loss: 968580.3972\n",
      "Epoch 470/500\n",
      " - 2s - loss: 1016508.6986 - val_loss: 968580.1505\n",
      "Epoch 471/500\n",
      " - 2s - loss: 1016508.6499 - val_loss: 968579.7659\n",
      "Epoch 472/500\n",
      " - 2s - loss: 1016508.6618 - val_loss: 968579.3275\n",
      "Epoch 473/500\n",
      " - 2s - loss: 1016508.6635 - val_loss: 968579.2034\n",
      "Epoch 474/500\n",
      " - 2s - loss: 1016508.6438 - val_loss: 968578.8768\n",
      "Epoch 475/500\n",
      " - 2s - loss: 1016508.6190 - val_loss: 968578.4922\n",
      "Epoch 476/500\n",
      " - 2s - loss: 1016508.6506 - val_loss: 968578.4044\n",
      "Epoch 477/500\n",
      " - 2s - loss: 1016508.5842 - val_loss: 968577.9345\n",
      "Epoch 478/500\n",
      " - 2s - loss: 1016508.5819 - val_loss: 968577.6749\n",
      "Epoch 479/500\n",
      " - 2s - loss: 1016508.5598 - val_loss: 968577.3960\n",
      "Epoch 480/500\n",
      " - 2s - loss: 1016508.6034 - val_loss: 968577.2172\n",
      "Epoch 481/500\n",
      " - 3s - loss: 1016508.4417 - val_loss: 968576.8621\n",
      "Epoch 482/500\n",
      " - 2s - loss: 1016508.4428 - val_loss: 968576.6890\n",
      "Epoch 483/500\n",
      " - 2s - loss: 1016508.4356 - val_loss: 968576.3044\n",
      "Epoch 484/500\n",
      " - 2s - loss: 1016508.4682 - val_loss: 968576.3371\n",
      "Epoch 485/500\n",
      " - 2s - loss: 1016508.4278 - val_loss: 968576.3519\n",
      "Epoch 486/500\n",
      " - 2s - loss: 1016508.4352 - val_loss: 968576.1626\n",
      "Epoch 487/500\n",
      " - 2s - loss: 1016508.4347 - val_loss: 968576.0730\n",
      "Epoch 488/500\n",
      " - 3s - loss: 1016508.4388 - val_loss: 968575.8999\n",
      "Epoch 489/500\n",
      " - 3s - loss: 1016508.4406 - val_loss: 968575.6388\n",
      "Epoch 490/500\n",
      " - 3s - loss: 1016508.4187 - val_loss: 968575.6388\n",
      "Epoch 491/500\n",
      " - 2s - loss: 1016508.3797 - val_loss: 968575.4465\n",
      "Epoch 492/500\n",
      " - 2s - loss: 1016508.3816 - val_loss: 968575.4465\n",
      "Epoch 493/500\n",
      " - 3s - loss: 1016508.4096 - val_loss: 968575.4465\n",
      "Epoch 494/500\n",
      " - 2s - loss: 1016508.4247 - val_loss: 968575.3600\n",
      "Epoch 495/500\n",
      " - 2s - loss: 1016508.3464 - val_loss: 968575.4465\n",
      "Epoch 496/500\n",
      " - 3s - loss: 1016508.4565 - val_loss: 968575.2734\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1016508.4259 - val_loss: 968575.2734\n",
      "Epoch 498/500\n",
      " - 2s - loss: 1016508.4280 - val_loss: 968575.2004\n",
      "Epoch 499/500\n",
      " - 3s - loss: 1016508.3848 - val_loss: 968575.2734\n",
      "Epoch 500/500\n",
      " - 2s - loss: 1016508.3812 - val_loss: 968575.2004\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "model_lstm = fit_lstm(X_train, Y_train, X_val, Y_val, epochs = 500, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lstm.model.predict(full_array_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [3384.0356],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696],\n",
       "       [2319.0696]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a003151588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df_sub['Json Yield'],y_pred,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4FNX6wPHvm14ILRTpoUkHkdBUBAQEEdvFgiJeFX8S\nBEQsoIhYsFwsNCnRi170WrChKKAgolQB4VKkV4XQa0hve35/zJJsQsoC2Uw2eT/Pk2enzzub3X1n\nzpk5R4wxKKWUUnnxsTsApZRSxZsmCqWUUvnSRKGUUipfmiiUUkrlSxOFUkqpfGmiUEoplS9NFCWA\niPQXkUV2x2E3EaktIvEi4luE+4wQESMifkW1T08Ska0i0uUS1iuxn0ER6SIiMXbHYSdNFIVMRP4S\nkSTnD9ZREZklImU8uU9jzKfGmBs9uY/iyPledz8/bow5YIwpY4zJsDMuuzgTVoPL2YYxppkx5rcC\n9nNBciytn8HSQhOFZ9xijCkDXAW0Bp6zOZ5LYudZckk5Q78Y+n6r4koThQcZY44CC7ESBgAiEigi\nb4vIARE5JiLRIhLsMv82EdkoIudEZK+I9HJOLyciH4jIERE5JCKvni9iEZEHRWSFc3iGiLztGoeI\nzBWRJ53D1UXkGxE5ISL7ReRxl+VeEpGvReQTETkHPJjzmJxxfOxc/28RGSMiPi5xrBSRqSISKyI7\nRKRbjnXzO4aVIjJRRE4BL4lIfRFZIiKnROSkiHwqIuWdy/8XqA384Lx6G5nzTFdEfhORcc7txonI\nIhGp5BLPA85jOCUiL+S8Qslx3MEi8o5z+VgRWeH6fwP6O/+nJ0XkeZf12onI7yJy1nncU0UkwGW+\nEZEhIrIb2O2cNllEDjo/A+tFpJPL8r4iMtr52Yhzzq8lIsuci2xyvh/3OJfv4/w8nRWRVSLS0mVb\nf4nIKBHZDCSIiJ/re+CMfZ0zjmMiMsG56vl9nXXuq6PrZ9C5bjMR+VlETjvXHZ3H+5rn98EZ2xqX\n/+dgsYrGgpzjX4l11R4rIstEpJnLdmeJyHQR+dEZ40oRuUJEJonIGedns3WO9+I5EdnmnP+f8/vJ\nJeY8v0MlljFG/wrxD/gL6O4crgn8CUx2mT8R+B6oCIQBPwBvOOe1A2KBHlhJvAbQ2DnvW+A9IBSo\nAqwFBjnnPQiscA5fDxwExDleAUgCqju3uR4YCwQA9YB9QE/nsi8BacDtzmWDczm+j4G5ztgjgF3A\nQJc40oERgD9wj/N4Krp5DOnAMMAPCAYaON+LQKAy1g/UpNzea+d4BGAAP+f4b8Be4Ern9n4D/uWc\n1xSIB65zvhdvO4+9ex7/12nO9WsAvsA1zrjO7/Pfzn20AlKAJs712gAdnMcUAWwHnnDZrgF+xvo8\nBDun3Q+EO9d5CjgKBDnnPYP1mWoEiHN/4S7bauCy7dbAcaC9M+Z/Ot+zQJf3byNQy2Xfme8p8Dsw\nwDlcBuiQ2/ucy2cwDDjijD3IOd4+j/c1v++Dj/N//hLQEDgDtHZZ92HnOoHAJGCjy7xZwEnn+x8E\nLAH2Aw8434tXgV9zfJa2ON+LisBK4FXnvC5AjEtMeX6HSuqf7QGUtD/nBy4eiHN+mX4ByjvnCZAA\n1HdZviOw3zn8HjAxl21WxfrxCXaZdu/5D3qOL6kAB4DrneP/ByxxDrcHDuTY9nPAf5zDLwHL8jk2\nXyAVaOoybRDwm0sch3EmKee0tcAAN4/hQF77di5zO7Ahx3tdUKIY4zL/MeAn5/BY4HOXeSHOY7sg\nUTh/HJKAVrnMO7/PmjmOuV8ex/AE8K3LuAFuKOC4z5zfN7ATuC2P5XImihnAuBzL7AQ6u7x/D+fy\n+T2fKJYBLwOV8jjmvBLFva7/p3yOK9/vg8u+TmMl2Ofy2VZ5Z0zlnOOzgH+7zB8GbHcZbwGczXHc\nUS7jvYG9zuEuZCWKfL9DJfVPyyU943ZjzGIR6Qx8BlQCzmKdFYcA60Xk/LKC9QMM1tnMgly2Vwfr\nDP2Iy3o+WFcO2RhjjIjMxvqyLgPuAz5x2U51ETnrsoovsNxl/IJtuqjkjONvl2l/Y51ln3fIOL89\nLvOru3kM2fYtIlWByUAnrDNHH6wfzYtx1GU4EevMGGdMmfszxiSKVeSVm0pYZ6V7L3Y/InIlMAGI\nxPrf+2GdkbrKedxPAwOdMRqgrDMGsD4j+cXhqg7wTxEZ5jItwLndXPedw0DgFWCHiOwHXjbGzHNj\nv+7GWND3AWPMXyLyK9YP97TMhawiy9eAu5zbcThnVcK6igU45rKvpFzGc95k4vpenP/c5uTOd6jE\n0ToKDzLGLMU6szlfZ3AS6wPazBhT3vlXzlgV32B9UOvnsqmDWGfjlVzWK2uMaZbLsgCfA3eKSB2s\nM6BvXLaz32Ub5Y0xYcaY3q5h53NIJ7GKZ+q4TKsNHHIZryEu33rn/MNuHkPOfb/unNbCGFMWq0hG\n8ln+YhzBKhoErDoIrOKe3JwEksn9f1OQGcAOoKHzGEaT/RjA5Tic9REjgbuBCsaY8lg/fOfXyesz\nkpuDwGs5/t8hxpjPc9t3TsaY3caYe7GKCccDX4tIaH7ruOy3nhvxFfR9QERuxrrK+AV4y2Xd+4Db\ngO5AOawrD7jwvb0YtVyGz39uc3LnO1TiaKLwvElADxFpZYxxYJVlTxSRKgAiUkNEejqX/QB4SES6\niYiPc15jY8wRYBHwjoiUdc6r77xiuYAxZgPWl3AmsNAYc/7sZy0Q56wkDHZWjDYXkbbuHIixbjv9\nEnhNRMKciehJsq5YwPpReVxE/EXkLqAJsOBij8EpDKsYL1ZEamCVz7s6hns/SLn5GrhFRK4Rq3L5\nJfL4kXH+3z4EJjgrMn2dFbiBbuwnDDgHxItIY2CwG8unAycAPxEZi3VFcd5MYJyINBRLSxE5n+By\nvh//BqJEpL1z2VARuVlEwtyIGxG5X0QqO4///GfI4YzNQd7v/Tygmog84aysDhOR9jkXKuj7INaN\nBzOBR7DqV24RkfM/yGFYJx6nsK5KXnfnmAowRERqikhF4Hngi1yWuazvkLfSROFhxpgTWBXAY52T\nRgF7gNVi3Vm0GKtiEmPMWuAhrAq+WGApWWfvD2AVG2zDKn75GqiWz64/wzrb+swllgygD9ZdWPvJ\nSiblLuKQhmGVK+8DVji3/6HL/DVYFY8nsYoG7jTGnC/SudhjeBm4Guu9mA/MyTH/DWCMWHf0PH0R\nx4AxZqvzWGZjXV3EY1X8puSxytNYlch/YJWZj8e978/TWGe/cVg/irn9+LhaCPyEdZPA31hXMq5F\nIhOwkvUirAT0AVYlOljJ7iPn+3G3MWYdVh3VVKz3ew+53MmWj17AVhGJxyoC7GeMSTLGJGL9b1c6\n99XBdSVjTBzWTQi3YBXJ7Qa65rGPPL8PwPvAXGPMAudnaCAw05kYP3a+P4ewPk+rL+K48vIZ1vu6\nD6vo7NWcCxTSd8jrnL8zRqnLJiIPAo8YY66zO5aLJdZDkWexioj22x2PKloi8hfWZ3ex3bEUR3pF\noUotEblFREKc5e5vY10x/GVvVEoVP5ooVGl2G1aF5WGs4rJ+Ri+xlbqAFj0ppZTKl15RKKWUypfX\nPXBXqVIlExERYXcYSinlVdavX3/SGFP5Utb1ukQRERHBunXr7A5DKaW8ioj8XfBSudOiJ6WUUvnS\nRKGUUipfmiiUUkrlSxOFUkqpfGmiUEoplS9NFEoppfLlsUQhIh+KyHER2ZLHfBGRKSKyR0Q2i8jV\nnopFKaXUpfPkcxSzsJo3/jiP+Tdhta/TEKtznRnOV6WUUpcqIxUSjkBaApzZA77+pKY6Cl4vHx5L\nFMaYZSISkc8itwEfOxthWy0i5UWkmrODG6WUUnnJSIW4g3BqO8Tuh7R4SDoBm2ZAenK2RScvb8/M\nNZdXYGPnk9k1yN4hS4xz2gWJQkQeBR4FqF27dpEEp5RStjMGYpbBgSWwdy6kxkHsPvfWrXAlpMXT\nqqEP236ocllheEUTHsaY97F6uyIyMlKbu1VKlSxpCXBqGyQeh9M7rSuE4xvh2HqIO5D3erW7WQkh\nsBwEhEGlFhzMaMa8X04x+GGrd9YuwJ7HzlCv3suXHJ6dieIQ2Tszr+mcppRS3sk4ICMNHGmQEmvV\nFcQfhuRT1mvSCTi9AxKOgV+QdYWQcBiSz+S9zdAroPo1UKYGVL8WanaykkJA9q7P09MdTJmyhrFj\nZ5OQkEbz5lXo1MnqSblu3QqXdVh2JorvgaEiMhurEjtW6yeUUsXaqe1weJV1BXBoOaSnwMElVp2B\ncYDJuLTt+gZYiaBshLWt4HBodA+UqwfV2oHkf4PqmjUxDBo0j02bjgHQt28T6tW7vOTgymOJQkQ+\nx7rqqSQiMcCLgD+AMSYaWAD0xupYPRF4yFOxKKVUNkf/gAO/Qmqs9WPvSIW0ROuMPz3JuiJwpFt/\np7dDyjnAzVJvH3/rh9+/DJSpDqHVILiSdQUQUhVCnPUFFRpCULh1xRBSucBkkJszZ5IYPfoX3ntv\nPcZARER5pk69iZtvvvKit5UfT971dG8B8w0wxFP7V0opHBmQkQJJJ2H/j3D8fxCz3Prxv1R1e1tn\n+n7B4B8KNa61fvArNQcfPxApvPgL8PLLS4mOXo+fnw9PP92RF17oTEiIf6Hvxysqs5VSpZgjHRJP\nQHpiVvm/Iw3O7rV+lJNOWYkg6SSknIW/f7aKb5JO5L/d8KbQqJ/1g+8bYP35BUNwZav+wMff+uH3\n8QPxta4MAsuDf3DRHHce0tMd+PlZVx9jxlzP/v1nee21G2je/PLubMqPJgqllGcZY5XdZ6RaP/BJ\nJyHhqFXRm3DUKu/PSLWKf9JTIPEoxB+xXhOOWcu7W+yTG78g8A20KpcrXwXNHoA6N1qJogjP/i9X\ncnI648ev4LvvdrJmzSMEBPhSqVIIc+f28/i+NVEopS6dMdaP/dG1WXf5nPvbuqXz7F7rnv+M1Mvc\niVhn+QFlnGf5zj9HmnUbaZ0eVh1AcGXrjD+gDPiFQOUWEFbbq5JBXn75ZR+DB89n9+7TACxcuIdb\nbmlUZPvXRKGUyl1aIhzfYL1mJMOhFdZ9/ulJVrl/4glrfnpiwdsSX/B1/sCfr8ANvcKq3A0o6yz6\nCbTmh1SGsJrWvNArrCTgUzp/qo4di+eppxbx6ad/AtCkSSVmzLiZzp0jijSO0vnuK6UulHwG9n4P\nvwy1ztTdFVjeumqo2AhqdYGydSCsDpStDeUbWGf4l3BHT2n3ySebGTbsR86eTSYoyI+xY6/nqaeu\nISDAt8hj0UShVGmTkQbn/rKuCOIOWK+bo60ngnN7DqBMdajSGhDr7L9eH/ALtK4AqrS25qtC53AY\nzp5NplevBkyb1rtQn4u4WJoolCrJ4g/Dsf9ZDcft+wESj8GJzXkvH94UWg6Cio2t2z79Q4su1lIu\nPj6V338/SI8e9QEYMKAl1auH0a1bXcTmehZNFEp5m0TnbaDJp62mIZJPQ9whOPknpJzJuoU08ZjV\nflBeKre0riaqtrEe/mrS3xpWRe6773YwbNiPnDiRwJYtj9GgQUVEhO7d69kdGqCJQqniy5EBJ7fA\n4ZVWsxGx+63XS9F0AJSrb1Ua1+oK1dqXiLuBvN3ff5/l8cd/4vvvdwIQGVmdlJR0m6O6kCYKpYqb\n7Z/BmtcgLgZSz+W9XNVICKqY9RdaFSo2gcCyzltIA6BsrRJzi2hJkpaWwaRJq3nppaUkJqYRFhbA\n6693Y/DgSHx9i1/FvyYKpex2ehfs+da6YtjxefbkULYO1LjOajW0YiOrMjm8me1PB6vL8/jjPxId\nvR6Au+9uxsSJPalePayAteyjiUIpOzjS4fdxsPqVC+f5Bli3m/ZdBBE9ij425XFPPNGBpUv/ZsKE\nnvTq1cDucAqkiUKpopR81uqucsXo7NMrNIRKLaHtSOuWU9/Cb9hN2cMYwyefbGbBgj189tk/EBEa\nNarEli2P4ePjHUWCmiiU8rStH8HRdXBgsdVpjatqHeH27yGkkj2xKY/aufMkgwfP59df/wKsW157\n924I4DVJAjRRKFX40hKtZqxXvQj75ue+TM8Pof6tVgc1qsRJSkrjjTdWMH78SlJTMwgPD+add27k\nppuKfzFTbjRRKHW5MtIgZqnV7tHeH6zbWY3jwuVu+cpqwC6wXNHHqIrM4sX7iIqax969VvemAwe2\nZvz47oSHh9gc2aXTRKHUpTizx0oOx9bDvnkQdzD7/MDyULkVHFkND26F8vXtiVMVuVWrDrJ37xma\nNatMdHQfrruutt0hXTZNFEpdjNR4eDeX2xjL1oG6N1sV0dXaWU89q1IhI8PBnj2nadTIqmcaNepa\nKlUK4ZFHrralAT9P0EShVEFSzlkV0ds/hZhlWdP9y0CVq6DNk1D/llLbFHZptmHDEaKi5rNv3xl2\n7hxKxYrBBAb68dhjbe0OrVDpJ1upnJLPwNE/YPc3Vr8Lu7+98Anp/mvhipL1Y6DcFxeXwtixvzJl\nylocDkONGmHs3XuaihVr2B2aR2iiUKVbarzVftLJLVbHPKd3wNk9VqN6riq3stpI8g+Fts9ohXQp\nZYxhzpztDB/+E4cOxeHjI4wY0YGXX+5CWFig3eF5jCYKVXr9Mgy2fGD12OZKfKznGyq3tPpcuLKv\n1YyGdr5T6j3xxE9MmbIWgLZtq/Pee31o3bqazVF5niYKVfoknYLpLg+4VW5pJYZq7a1mtsNqQ1B5\n++JTxdYddzTho4828frr3Rg0qE2xbMDPEzRRqNIj4Rh8/4/sTXX7BsKAjdq6qsrVihUH+PXX/bzw\nQmcAunSJ4MCBEZQtW3KLmXKjiUKVfLH7YfP7sOFdSEuwpgWFQ5snoMMYe2NTxdKpU4mMGrWYDz7Y\nAEC3bvW45ppaAKUuSYAmClVSZaTBkmFwZA2c2Jg1vf6tcN1rUKm5fbGpYssYw8cfb+Lpp3/m5MlE\n/P19ePbZ62jd+gq7Q7OVJgrl/VLjYNfXsGykVf/gF3RhBXXj+6DVYKh5nT0xqmJv+/YTDB48n6VL\n/waga9cIpk+/mcaNtcFGTRTKe53aBkufhv0/Zp9+PkmUqQnNH4Q2T2nltCrQhAm/s3Tp31SuHMKE\nCT3p378FonVXgCYK5Y0O/w4L7ofYfdmnV20D1a+xnpQOqwU+JaP5BOU5sbHJlCsXBMAbb3QnNDSA\nsWM7U7Gi9iDoShOF8h7GwLx7YNdXWdPK1YXKV1nNdutVg3LT4cNxjBixkM2bj7FpUxQBAb5UqhTC\npEm97A6tWNJEoYqntCQ4t996YvrEJji+EfYvyL7MI/usRKGUmzIyHEyf/gfPP7+EuLhUQkL8+d//\njtChQ027QyvWNFGo4uHoOjiwBDZHQ8JRqwkNR/qFy/n4QcXG0H8d+JW+2xTVpVu//jCDBs1j/foj\nANx6ayPeffcmatfW5lgK4tFEISK9gMmALzDTGPOvHPPLAZ8AtZ2xvG2M+Y8nY1LF0PbPYUF/wGSf\nXq4ehDexipYqt4JKLawrCE0Q6iK99NJvjBu3DIfDUKtWWd599yZuu62x3WF5DY8lChHxBaYBPYAY\n4A8R+d4Ys81lsSHANmPMLSJSGdgpIp8aY1I9FZcqZrZ9AgsfAgw0ugeqdYDyDaB2N/DXCkVVOOrV\nq4AIPPVUR156qQtlygTYHZJX8eQVRTtgjzFmH4CIzAZuA1wThQHCxLoHrQxwGsilvEGVOMYBS4bD\nxqnWeNuRcP14e2NSJca+fWf4449D3HOP9WDlgAEtad++RmbnQurieDJR1ABc+4eMAdrnWGYq8D1w\nGAgD7jHmws6GReRR4FGA2rW9v1vBUuncQatPh4wU629TNGz72KpzuGEqtHzU7ghVCZCamsHbb69i\n3LhlGGNo06Y6DRpUREQ0SVwGuyuzewIbgRuA+sDPIrLcGJOtlxhjzPvA+wCRkZHmgq2o4smRblVQ\nr3wBjq7NfZlrX4VWg4o2LlUiLVv2N1FR89i+/SQA/fu3KJXtMnmCJxPFIaCWy3hN5zRXDwH/MsYY\nYI+I7AcaA3n8qiivcGw9rHvH2UOcS3WTXxBUaGxVRodUhQa3Q5P+9sWpSoSTJxN55pmfmTXLatOr\nYcOKzJhxM9261bM5spLDk4niD6ChiNTFShD9gPtyLHMA6AYsF5GqQCMgx+O2ymscWgmrXrL6lz6v\nQiNo3M9qa6nilbaFpkquqKh5fPPNdgIDfRk9uhMjR15LUJDdhSUli8feTWNMuogMBRZi3R77oTFm\nq4hEOedHA+OAWSLyJyDAKGPMSU/FpDwkZ4IICIMWj8LVw6BsHVtDUyWTw2Hw8bHaYXrttRtISkpn\n0qSeNGwYbnNkJZNYpT7eIzIy0qxbt87uMEo3Y+DMbutJ6d9GZE0PKAtXD4ern4DgivbFp0qsxMQ0\nxo1bysaNx1iw4D5ttO8iiMh6Y0zkpayr12fKfWmJsPMLWPjwhfM6vKAJQnnU/Pm7GDr0R/766ywi\nsHbtIdq316Y3ioImCpU344DTO2Drx7D7azi7N/v80GqQcATu/R2qd7AnRlXixcScY/jwn5gzZzsA\nrVpVJTq6jyaJIqSJQmWXEgvJp+HgUljxnNXuUk4dxkLbZyCgTNHHp0qV6dP/YNSoxcTHpxIa6s+4\ncV0ZNqw9fn4+dodWqmiiUJaEY7B4MOyda11JuGo+EJo9CNXaga82faCKzsmTicTHp3LHHY2ZPLkX\ntWppA3520ERRmiWegE0zYNWLF86rGgm1ukLHsXrloIrM2bPJ7NhxMrPZ71GjrqVduxr06tXA5shK\nN00UpdW5v2FmvexXDxG9oOOLWt+gipwxhi++2MqIEQvJyHCwY8dQKlYMJjDQT5NEMaCJorRJibXu\nWto9xxoPqWJ1H9p8INTvY29sqlTas+c0Q4YsYNEi62aJa66pRWxssnZHWoy4lShEJACobYzZ4+F4\nlCdt/Rh++mf2aff/D8Jq2BOPKtVSUtJ5882VvPbaclJSMqhQIYg33+zBww+3znyYThUPBSYKEbkZ\nmAAEAHVF5CrgRWPMHZ4OThWShGMQfUX2ac0HQrdp2gmQss0993zN3Lk7AXjggVa89VYPqlQJtTkq\nlRt3rihewWoe/FcAY8xGEdFCQ2+QnmI9/7Dg/qxpYbWsvqZ9tNRR2euJJzqwc+cppk/vTdeu2vd5\ncebOr0WaMeZsjkflvavdj9Jo5VhYPS77tD5fQqO77IlHlWoOh+HDDzewffsJ3nmnJwBdukSwZctg\nfH31mYjizp1EsV1E7gZ8nC3BPg6s9mxY6rLs+iZ7kqh8FXSdBLU62xeTKrX+/PMYUVHzWbXK6sfs\ngQda0aqVVRSqScI7uJMohgJjAQcwB6s12NGeDEpdIkcGLBlm9R4HVl8PvT4CH19741KlUkJCKi+/\nvJQJE34nI8NwxRVlmDSpJy1bVrU7NHWR3EkUPY0xo4BR5yeIyD+wkoYqLtISYYpLRWCLR6DH+6Ct\nayob/PDDToYO/ZEDB2IRgSFD2vLaazdQrlyQ3aGpS+DOdd+YXKY9X9iBqMtwdF32JNFlItz4b00S\nyjbffbeDAwdiad36CtaseYSpU3trkvBieV5RiEhPoBdQQ0QmuMwqi1UMpeyWEgsbpsKa17Km1bsF\n2jxhX0yqVEpPd3Do0Dnq1CkPwPjxPWjduhpRUZHagF8JkF/R03FgC5AMbHWZHgc868mgVAH2/wh/\nvAVHVkN6kjWtzo3WVUTZ2vbGpkqd1atjiIqaR0pKBps2RREQ4EulSiEMHdrO7tBUIckzURhjNgAb\nRORTY0xyEcakcpNyDhbcB/vmZ59erT20GgxNH9CiJlWkzpxJYvToX3jvvfUYAxER5fnrr7NceaV2\nR1rSuFOZXUNEXgOaApmFjMaYKz0Wlcou8STMqJx9WvVroN1z2j6TKnLGGD7/fAsjRizk+PEE/Px8\neOaZaxgz5npCQvztDk95gDuJYhbwKvA2cBPwEPrAXdHZ/rl1JXFeo3ug5wfgr00dKHv07z+Hzz/f\nAkCnTrWZMeNmmjWrYnNUypPcqWUKMcYsBDDG7DXGjMFKGMpT4mJgzevw8VXZk0Tfn6DPbE0Syla9\nejUgPDyYDz+8ld9+e1CTRCngzhVFioj4AHtFJAo4BIR5NqxSKi0Rlj4Dm6ZfOO/hXVChYdHHpEq9\nxYv3sXfvaQYNigRgwICW9OlzpTYDXoq4kyhGAKFYTXe8BpQDHvZkUKVOWhJs+RCWDHVOELjyLoi4\nEcJqQu3u+nS1KnLHjsXz5JOL+OyzPwkM9KV793rUr18REdEkUcoUmCiMMWucg3HAAAAR0Q4MCsvO\nr2De3dmn3f2rtsukbONwGN5/fz3PPruY2NgUgoL8GDv2eu2vuhTLN1GISFugBrDCGHNSRJphNeVx\nA1CzCOIr2ZJOZU8Sje+Fji9BRb2hTNlj06ajDBo0jzVrDgFw000NmDq1N/XqVbA5MmWn/J7MfgPo\nC2wCxojIPOAxYDwQVTThlWDGwA/OJr/9Q2HwMa2kVrYbOXIxa9Yconr1MCZP7kXfvk0QfT6n1Mvv\niuI2oJUxJklEKgIHgRbGmH1FE1oJ98OdcPBXa/jeVZoklC2MMSQmphEaGgDAlCm9iI5ex8svd6Vs\nWe39UFnyuz022RiTBGCMOQ3s0iRRSA6thN3OxnfDakHllvbGo0qlv/8+y223zebWW2djjPVoVKNG\nlZg4sZcmCZVNflcU9UTkfFPigtVfdmbT4saYf3g0spIoZrnVX8SJTda4XwgM3GNvTKrUSUvLYOLE\n1bz88lISE9MICwtg9+7T2vSGylN+iaJvjvGpngykxFv9Gqx0abG9zQjo+CL4BtgXkyp1Vq48QFTU\nfLZsOQ7APfc0Y8KEnlSvro9Gqbzl1yjgL0UZSIkWuz97kog6AqFX2BePKpWGDVvA1Kl/AFCvXgWm\nTetNr14NbI5KeQN3HrhTlyP5LMyslzU+LA4CytgXjyq1KlcOxd/fh1GjrmX06E4EB2sDfso9Hu1R\nRER6ichOEdkjIrn2YSEiXURko4hsFZGlnoynyBkD01zuP++7UJOEKjI7dpxk0aK9meOjRl3L5s2D\nGTfuBk2Dp/5iAAAgAElEQVQS6qK4nShE5KJugxARX2AaVgOCTYF7RaRpjmXKA9OBW40xzYC7LmYf\nxd571bOGb/rYapJDKQ9LSkrjhReW0LLlDO6/fw6nT1udWwUG+tG4cSWbo1PeqMBEISLtRORPYLdz\nvJWIvOvGttsBe4wx+4wxqcBsrGczXN0HzDHGHAAwxhy/qOiLs+mVIeGoNRzeFJoOsDceVSosWrSX\nFi1m8Oqry0lLc3DrrY20Pyt12dypo5gC9AG+AzDGbBKRrm6sVwPrIb3zYoD2OZa5EvAXkd+wWqSd\nbIz52I1tF29r34Skk9Zw/dvg9u/sjUeVeEeOxDFixEK++MLqtbhZs8pER/fhuuu0a1x1+dxJFD7G\nmL9zPMafUYj7bwN0A4KB30VktTFml+tCIvIo8ChA7drF/IO/YzYsH5U1rklCFYF//ONLVq+OITjY\nj5de6sKIER3w99cWh1XhcKeO4qCItAOMiPiKyBPAroJWwuq3opbLeE3nNFcxwEJjTIIx5iSwDGiV\nc0PGmPeNMZHGmMjKlSvnnF28/PZk1vCThZVPlbrQ+aepAf71r2706XMl27YNYeTIazVJqELlTqIY\nDDwJ1AaOAR2c0wryB9BQROqKSADQD/g+xzJzgetExE9EQrCKpra7G3yxs2cuJByxhrvPAPHoTWWq\nlIqLS2HEiJ8YNGhe5rTOnSP44Yd7iYgob2NkqqRyp+gp3RjT72I3bIxJF5GhwELAF/jQGLPV2Use\nxphoY8x2EfkJ2Aw4gJnGmC0Xu69i4a+FMPd2azikKrT4P3vjUSWOMYY5c7YzfPhPHDoUh5+fD6NH\nd9LkoDxOXC9fc11AZC+wE/gC6w6luKIILC+RkZFm3bp1doZwIUcGTHTJuYNPQIjehqgKz/79Zxg6\n9EcWLNgNQLt2NYiOvpnWravZHJnyFiKy3hgTeSnrFlg2YoypD7yKVen8p4h8JyIXfYVRon3sUq0S\ndUSThCo0xhjGj19Bs2bTWbBgN+XKBTJ9em9WrXpYk4QqMm4VohtjVhljHgeuBs4Bn3o0Km/y1yI4\nZd2SSItHtA0nVahEhF27TpGUlM699zZnx46hDB7cFl9frf9SRafAOgoRKYP1oFw/oAlWBfQ1Ho7L\ne2ydlTV8479tC0OVHCdPJnL0aDzNm1cBYPz4HvTr15wePerbHJkqrdypzN4C/AC8aYxZ7uF4vIsx\nsONza/jGD+yNRXk9YwwffbSJp59eROXKoWzaFEVAgC+VKoVoklC2cidR1DPGODweiTfaOC1ruFHJ\naqZKFa3t208QFTWfZcv+BqBVqys4cyaJqlW1EUllvzwThYi8Y4x5CvhGRC64NUp7uMPqZwIgoCwE\naMcv6uIlJqbx2mvLeOutVaSlOahcOYQJE3rSv38LRBtpUsVEflcUXzhftWe73Oz6GtZPsIZvn2tv\nLMorGWO44YaPWLPGarBg0KA2vPFGNypUCLY5MqWyy6+Hu7XOwSbGmGzJwvkgXentAS81Hn5wFjUF\nlIUa19kbj/JKIsJjj7UlMTGN997rQ8eOtQpeSSkbuHOP3cO5TBtY2IF4lWUjs4YfOwE+2lGgKlhG\nhoN3313DhAm/Z04bMKAl69c/qklCFWv51VHcg3VLbF0RmeMyKww46+nAiq2fB8Hm963hpgPAN8De\neJRXWLfuMFFR81i//giBgb7069ec6tXDEBFtwE8Ve/mdCq8FTmG1+upyew9xwAZPBlVsrZ+UlSSq\ntYdes2wNRxV/sbHJjBmzhGnT/sAYqFWrLO++exPVq+vND8p75FdHsR/YDywuunCKsbgY+G2ENewX\nAvf+jnYdpvJijOGrr7bxxBM/ceRIPL6+wogRHXjxxS6UKaNXocq75Ff0tNQY01lEzgCut8cKYIwx\nFT0eXXFhDLzvUoY8KEaThCrQe++t58iReDp0qEl09M20aqXNuyjvlF/R0/nuTrWFu9kudzW1HQlB\nFeyLRRVbKSnpnD2bTNWqZRARpk/vzW+//cX//V8bfHz0xEJ5rzzvenJ5GrsW4GuMyQA6AoOA0CKI\nrXhIPguHV1nDVdvA9ePtjUcVS0uX/sVVV73HfffNyex5rlGjSgwaFKlJQnk9d26P/Q6rG9T6wH+A\nhsBnHo2qONmX1YsY/dfmvZwqlU6cSODBB7+jS5eP2LHjJAcPxnLsWILdYSlVqNx5AMBhjEkTkX8A\n7xpjpohI6bnr6ccB1mvZCO3aVGVyOAz/+c8GRo5czOnTSQQG+jJ6dCdGjryWoCB9rkaVLG51hSoi\ndwEDAGdfn/h7LqRi5OgfWcPXvmJfHKpYMcbQs+cnLF68D4Du3esxfXpvGjYMtzkypTzD3Sezu2I1\nM75PROoCn3s2rGJi1YtZw00H2BeHKlZEhE6dalO1aiifffYPFi26X5OEKtEK7DMbQET8gAbO0T3G\nmHSPRpWPIusz+9QOmNXEGu78DkQ+6fl9qmJr/vxdpKU5uP32xoB1h1NSUjrlywfZHJlS7rmcPrPd\n6eGuE/Bf4BDWMxRXiMgAY8zKS9mh1zh/pxNA62H2xaFsFRNzjuHDf2LOnO1UqhTC9dfXoWLFYAID\n/QgM1LoIVTq480mfCPQ2xmwDEJEmWInjkjKTV0hLgJ//zxruOhl8S0eVjMqSnm414Dd27G/Ex6cS\nGurP6NHXUbZsoN2hKVXk3EkUAeeTBIAxZruIlOw2CL7qDsYBPv7QuJ/d0agitnbtIQYNmsfGjUcB\nuOOOxkye3ItatcrZHJlS9nAnUfxPRKKBT5zj/SnJjQI60uHMbmu4wwsQUsXeeFSRcjgMDz00l23b\nTlC7djmmTr2JW25pZHdYStnKnUQRBTwOnO+EYTnwrscistumaEg+Bf5loMMYu6NRRcAYQ0pKBkFB\nfvj4CNOm9ebHH3czdmxnQkNL9sWzUu7IN1GISAugPvCtMebNognJRqlxsMRZcV27mzb8Vwrs2XOa\nxx6bT61aZfngg9sA6NIlgi5dIuwNTKliJM/nKERkNFbzHf2Bn0Ukt57uSpZ3y2YNd3rDvjiUx6Wk\npPPKK0tp3nw6P/+8j+++28mpU4l2h6VUsZTfFUV/oKUxJkFEKgMLgA+LJiwbODKyhqt1gPAm9sWi\nPGrJkv0MHjyfXbtOAfDPf7birbd6EB4eYnNkShVP+SWKFGNMAoAx5oRICW/oaN07WcP3/Z73cspr\nZWQ4eOihufz3v5sBaNQonOjoPlrMpFQB8ksU9Vz6yhagvmvf2caYf3g0sqK2fJT1Wq6evXEoj/H1\n9cHPz4egID/GjOnE009fow/NKeWG/L4lfXOMT/VkILaKi8ka1n6wS5Q//zxGcnI6bdvWAOCtt3rw\n/POdqF+/9HTQqNTlyq/P7F+KMhBbHXVpO6pmJ/viUIUmISGVl176jYkTV9OwYTibNkUREOBLeHiI\n1kUodZH0uhvgiLNO4qqh9sahCsX33+9k2LAfOXAgFhHo3r0uaWkZBAT42h2aUl7JoxXUItJLRHaK\nyB4ReTaf5dqKSLqI3OnJePJ0aIX1GtHTlt2rwnHgQCy33z6b226bzYEDsVx9dTXWrv0/3n23tz44\np9RlcPuKQkQCjTEpF7G8LzAN6AHEAH+IyPeu7Ua5LDceWOTutguVMVktxZapYUsI6vJlZDjo0mUW\n+/efJSwsgFdfvYHHHmuLn1/JvllPqaJQ4LdIRNqJyJ/Abud4KxFxpwmPdlh9V+wzxqQCs4Hbcllu\nGPANcNz9sAvR0qezhitqmz7e5nx/Kr6+Prz0UhfuvLMp27cP4fHH22uSUKqQuPNNmgL0AU4BGGM2\nYfV4V5AawEGX8RjntEwiUgO4A5iR34ZE5FERWSci606cOOHGrt10agesn2ANh9UGf63k9BZnziQR\nFTWP119fnjltwICWfPXVXdSoUTafNZVSF8udROFjjPk7x7SMXJe8eJOAUcYYR34LGWPeN8ZEGmMi\nK1euXDh7No6sHuwA+v5YONtVHmWM4dNPN9O48TTee28948evJDY2GbC6KFVKFT536igOikg7wDjr\nE4YBu9xY7xBQy2W8pnOaq0hgtvMLXgnoLSLpxpjv3Nj+5fn8uqzh3p9BeFOP71Jdnl27TvHYY/P5\n5Zf9AHTqVJsZM26mXDntjlQpT3InUQzGKn6qDRwDFjunFeQPoKGI1MVKEP2A+1wXMMbUPT8sIrOA\neUWSJI5vyrolts0IaHKvx3epLl16uoNXX13GG2+sIDU1g/DwYN56qwcPPniVXkUoVQQKTBTGmONY\nP/IXxRiTLiJDgYWAL/ChMWariEQ550df7DYLzVxnnXqdHtBlgm1hKPf4+grLlx8gNTWDhx++ivHj\ne1CpktYnKVVUCkwUIvJvwOScbox5tKB1jTELsFqddZ2Wa4IwxjxY0PYKTcIR67WRdnNaXB07Fk9y\ncjp16pRHRIiOvpkjR+K5/vo6doemVKnjTmX2YuAX599KoArg9vMUxU78YchItYab3m9vLOoCDoch\nOnodjRpNZeDA7zNvf23YMFyThFI2cafo6QvXcRH5L7DCYxF52r551mt4U/DVp3WLk40bjxIVNY81\na6x7HgICfImPTyUsLNDmyJQq3S6lrae6QNXCDqTIHHZWYp87YG8cKlNcXAovvvgbkyevweEwVK8e\nxuTJvejbt4lWVitVDLhTR3GGrDoKH+A0kGe7TcXe+eY62o+2Nw4FQGpqBldf/T579pzGx0cYPrw9\nr7zSlbJl9SpCqeIi30Qh1ulcK7Kef3CY84XG3ujkVjjjfASkhjYnXhwEBPgyYEBLfvhhF9HRN9Om\nTXW7Q1JK5SAF/e6LyBZjTPMiiqdAkZGRZt26dQUvmFNGGkxyqZMYngR++qBWUUtLy2DixNXUrl2O\nfv2sj1Vqaga+voKvr7bNpJSniMh6Y0zkpazrTh3FRhFpbYzZcCk7KDaWP5c13OsjTRI2WLnyAFFR\n89my5TiVK4fQp8+VlCkToP1EKFXM5ZkoRMTPGJMOtMZqInwvkIDVf7YxxlxdRDEWjvXvZA03HWBf\nHKXQ6dNJjBr1MzNnWuca9epVYPr03pQpo3edKeUN8ruiWAtcDdxaRLF4zmmXpqke3gV6J02RMMbw\n3/9u5qmnFnHyZCL+/j6MGnUto0d3IjjY3+7wlFJuyi9RCIAxZm8RxeI5n3fIGq7Q0L44Spm0NAdv\nvLGCkycT6dy5DjNm3EyTJoXU+q9Sqsjklygqi8iTec00xnhHI0mHVkHyGWu4bm97YykFkpLSSE3N\noFy5IAICfHn//T7s23eGBx5opc9EKOWl8rvNxBcoA4Tl8ecddn1lvda5Ef4x395YSriFC/fQvPkM\nnnxyYea0Tp3q8M9/aiuvSnmz/K4ojhhjXimySDzh7F7432Rr+JqXbA2lJDtyJI4RIxbyxRdbAQgN\n9ScxMY2QEK2HUKokyO+KwvtPATe/DxioGgnVO9odTYmTkeFg6tS1NG48jS++2EpwsB/jx3dn/fpH\nNUkoVYLkd0XRrcii8JS/nEUgZfRp38KWnJzO9df/hz/+OAxAnz5X8u67NxERUd7myJRShS3PRGGM\nOV2UgRS6uENwYhP4h0LvT+yOpsQJCvKjefMqHDkSz5Qpvbj99sZaD6FUCXUprcd6h0PLrdcanSDA\ne+reiytjDHPmbKdq1TJcd11tACZM6Imvr2gz4EqVcCU3UWyaYb3WvN7eOEqA/fvPMHTojyxYsJvG\njSuxceMgAgP9KF9em0FRqjQomYnCGDi13Rqu1dXeWLxYamoG77yzinHjlpGUlE65coEMH94ePz9t\nvE+p0qRkJor0ZEg6YQ1Xa29vLF5q+fK/iYqaz7Zt1vt4330teOedG7niijI2R6aUKmolM1EkHs0a\n1grWi5aUlMadd37F8eMJNGhQkenTe9OjR327w1JK2aRkJorjzhbR/YLtjcOLGGPIyDD4+fkQHOzP\nhAk3smvXKZ57rhNBQSXzY6KUck/J/AXY5rwdtmyErWF4i23bThAVNY8ePerxwgudAejfv6XNUSml\niouSWSt5dK31WqW1vXEUc4mJaYwe/QutWkWzfPkBZs7cQEpKut1hKaWKmZJ3RXHuIMQ7u/juOsne\nWIqxH3/czZAhC9i//ywAgwa14Y03uhEYWPI+Ekqpy1PyfhXWvWW9hlSFEO37IKeEhFQefHAuX3+9\nDYCWLasSHX0zHTvWsjkypVRxVfISxYZ37Y6gWAsJ8ef06SRCQ/15+eUuDB/eQZ+LUErlq2QlivSU\nrOEbZ9oXRzGzbt1hypcPokGDiogIM2fegq+vD7Vrl7M7NKWUFyhZp5Jp8VnD9fvYF0cxERubzLBh\nC2jX7t9ERc3DGANA3boVNEkopdxWsq4odn9jvZapYW8cNjPG8OWXW3niiYUcPRqPr69w9dXVSE93\n4O/va3d4SikvU7ISxbb/Wq/+ofbGYaO9e08zZMgCFi7cC0DHjjWJju5Dy5ZVbY5MKeWtSlaiOLbe\neo3oZW8cNomLSyEy8t+cPZtM+fJBjB/fnUceuRofH23GRCl16TyaKESkFzAZ8AVmGmP+lWN+f2AU\nVrerccBgY8ymS95herL12ujuS96ENwsLC2TEiA7s2XOat9++kSpVSu+VlVKq8HgsUYiILzAN6AHE\nAH+IyPfGmG0ui+0HOhtjzojITcD7wKU195oaD1iVtVRtc+mBe5ETJxJ45pmf6datLgMGtALghReu\n157mlFKFypN3PbUD9hhj9hljUoHZwG2uCxhjVhljzjhHVwM1L3lvfy+2XsNqgV/J7lDH4TDMnPk/\nGjWaykcfbeL555eQlpYBoElCKVXoPFn0VAM46DIeQ/5XCwOBH3ObISKPAo8C1K5dO/e1/15ovZbw\niuwtW44TFTWPlSutt7Z793pMn95b72ZSSnlMsajMFpGuWIniutzmG2PexyqWIjIy0uS6kZNbrNca\nnTwRou2SktJ46aXfmDBhNenpDqpWDWXixJ7069dcryKUUh7lyURxCHBtQKimc1o2ItISmAncZIw5\nddl7LaFdn/r4CN9/v4uMDAePPRbJa6910z6rlVJFwpOJ4g+goYjUxUoQ/YD7XBcQkdrAHGCAMWbX\nZe0tdp/1Wr3jZW2mOImJOUdIiD8VKwYTGOjHrFlWFU/79pdelaOUUhfLY5XZxph0YCiwENgOfGmM\n2SoiUSIS5VxsLBAOTBeRjSKy7pJ2lp4M8YfBxw/CvP9HND3dwcSJv9OkyTSeeWZR5vT27WtqklBK\nFTmP1lEYYxYAC3JMi3YZfgR45LJ3lHTSeg2pYiULL7ZmTQyDBs1j06ZjAMTGppCe7tAWXpVStvHu\nX9XzzndU5BdibxyX4ezZZEaP/oXo6HUYA3XqlGPq1N706XOl3aEppUq5kpEoDvxqvSafyX+5YurM\nmSSaNp3O0aPx+Pn58NRTHXnhhesJDQ2wOzSllCoBiSItCVa/bA13ftveWC5RhQrB3HRTA3btOsWM\nGTfTooU24KeUKj68P1Hs+yGrjaemA+yNxU0pKemMH7+Szp3r0LlzBABTp/YmKMhPG/BTShU73p8o\njqy1XjuMBZ/i/3TykiX7GTx4Prt2naJJk0r8+edgfH19CAnxtzs0pZTKlfcnisSj1mv5evbGUYDj\nxxN46qlFfPLJZgAaN67E9Ok34+urdzMppYo3708U8Yet15DiWa5/vgG/UaMWc/ZsMkFBfowZ04ln\nnrmWgIDifwWklFLenSjSEuDQcmu4YmN7Y8lDbGwyzz+/hLNnk+nZsz7TpvWmfv2KdoellFJu8+5E\n8dfP4EiH8g2gXITd0WRKSEjFz8+HwEA/KlQIJjr6ZjIyDHfd1VQb8FNKeR3vLiDf/J71Wozad/r+\n+500bTqdN99cmTmtb9+m3H13M00SSimv5N2JIvWc9VoM6icOHIjl9ttnc9ttszlwIJaFC/ficOTe\nIrpSSnkT700UCcfg8CpruPVQ28JIS8vg7bdX0aTJNObO3UlYWACTJ/di6dIH9ZkIpVSJ4L11FDHL\nrNeQKlC2ji0hnDyZSLduH7N5s9WA3113NWXixJ7UqFHWlniUUsoTvDdRbJxqvZZvYFsI4eHBVKoU\nQt265Zk6tTe9eze0LRZV/KSlpRETE0NycrLdoahSJCgoiJo1a+LvX3gP8XpvovB19u4Wlkcf2h5g\njOHTT/+kXbsaXHllOCLCJ5/cQblyQfpktbpATEwMYWFhRERE6I0MqkgYYzh16hQxMTHUrVu30Lbr\nnXUUCUfhsPOuok6vF8kud+48Sffu/2XAgG957LH5GGNVVFerFqZJQuUqOTmZ8PBwTRKqyIgI4eHh\nhX4V651XFDu/sh62q9YeykZ4dFfJyem88cZy/vWvlaSmZhAeHsz997f06D5VyaFJQhU1T3zmvDNR\npCVYrzW7gAe/iIsX72Pw4Pns2XMagIcfvoo33+xBeLj3dpCklFIXyzuLnk5vs159Pdexz7Fj8fTp\n8xl79pymadPKLFv2IB98cJsmCeVVfH19ueqqq2jevDm33HILZ8+ezZy3detWbrjhBho1akTDhg0Z\nN25cZpEqwI8//khkZCRNmzaldevWPPXUU3YcQr42bNjAwIED7Q4jX2+88QYNGjSgUaNGLFy4MNdl\nNm7cSIcOHbjqqquIjIxk7VqrVexTp07RtWtXypQpw9Ch2R8D6N69O2fOFFFnbcYYr/pr06aNMTOu\nMOZtjFkx1hSmjAyHcTgcmePjx68wb7yx3KSkpBfqflTpsG3bNrtDMKGhoZnDDzzwgHn11VeNMcYk\nJiaaevXqmYULFxpjjElISDC9evUyU6dONcYY8+eff5p69eqZ7du3G2OMSU9PN9OnTy/U2NLS0i57\nG3feeafZuHFjke7zYmzdutW0bNnSJCcnm3379pl69eqZ9PQLf0969OhhFixYYIwxZv78+aZz587G\nGGPi4+PN8uXLzYwZM8yQIUOyrTNr1qzM/2dOuX32gHXmEn93vbPoKcHZtHjdmwptkxs3HiUqah5D\nhrRlwIBWAIwceW2hbV+Vcu94qIj0Kfef/u/YsSObN1vN3H/22Wdce+213HjjjQCEhIQwdepUunTp\nwpAhQ3jzzTd5/vnnadzYamzT19eXwYMHX7DN+Ph4hg0bxrp16xARXnzxRfr27UuZMmWIj48H4Ouv\nv2bevHnMmjWLBx98kKCgIDZs2MC1117LnDlz2LhxI+XLlwegYcOGrFixAh8fH6Kiojhw4AAAkyZN\n4tprs38f4+Li2Lx5M61aWd/XtWvXMnz4cJKTkwkODuY///kPjRo1YtasWcyZM4f4+HgyMjJYunQp\nb731Fl9++SUpKSnccccdvPyy1Uvm7bffzsGDB0lOTmb48OE8+uijbr+/uZk7dy79+vUjMDCQunXr\n0qBBA9auXUvHjtmbHRIRzp2zWpqIjY2levXqAISGhnLdddexZ8+eC7Z966230qlTJ55//vnLitEd\n3pcoTEbWcJXWl725uLgUXnzxNyZPXoPDYUhJyeD++1tqJaQqUTIyMvjll18yi2m2bt1KmzZtsi1T\nv3594uPjOXfuHFu2bHGrqGncuHGUK1eOP//8E8CtopCYmBhWrVqFr68vGRkZfPvttzz00EOsWbOG\nOnXqULVqVe677z5GjBjBddddx4EDB+jZsyfbt2/Ptp1169bRvHnzzPHGjRuzfPly/Pz8WLx4MaNH\nj+abb74B4H//+x+bN2+mYsWKLFq0iN27d7N27VqMMdx6660sW7aM66+/ng8//JCKFSuSlJRE27Zt\n6du3L+Hh4dn2O2LECH799dcLjqtfv348++yz2aYdOnSIDh06ZI7XrFmTQ4cOXbDupEmT6NmzJ08/\n/TQOh4NVq1YV+D5WqFCBlJQUTp06dUGMhc37EkVqfNawX+Alb8YYw3ff7eDxx38iJuYcPj7C8OHt\neeWVrpokVOG7iDP/wpSUlMRVV13FoUOHaNKkCT169CjU7S9evJjZs2dnjleoUKHAde666y58fa2+\nWO655x5eeeUVHnroIWbPns0999yTud1t27ZlrnPu3Dni4+MpU6ZM5rQjR45QuXLlzPHY2Fj++c9/\nsnv3bkSEtLS0zHk9evSgYkWref9FixaxaNEiWre2TjTj4+PZvXs3119/PVOmTOHbb78F4ODBg+ze\nvfuCH+GJEye69+ZchBkzZjBx4kT69u3Ll19+ycCBA1m8eHGB61WpUoXDhw9rorhAepL16h96yZs4\neTKRhx6ay7x5uwCIjKzOe+/14eqrqxVGhEoVG8HBwWzcuJHExER69uzJtGnTePzxx2natCnLli3L\ntuy+ffsoU6YMZcuWpVmzZqxfvz6zWOdiuZ5s5bynPzQ067vbsWNH9uzZw4kTJ/juu+8YM2YMAA6H\ng9WrVxMUFJTvsblu+4UXXqBr1658++23/PXXX3Tp0iXXfRpjeO655xg0aFC27f32228sXryY33//\nnZCQELp06ZLr8wgXc0VRo0YNDh48mDkeExNDjRo1Llj3o48+YvLkyYCVSB955JE8j9vV+WI2T/O+\nu54c6dZrlasveRNhYQHs2XOasmUDmTr1JlavHqhJQpVoISEhTJkyhXfeeYf09HT69+/PihUrMs9a\nk5KSePzxxxk5ciQAzzzzDK+//jq7dlknUw6Hg+jo6Au226NHD6ZNm5Y5fr7oqWrVqmzfvh2Hw5F5\nhp4bEeGOO+7gySefpEmTJplnxjfeeCPvvvtu5nIbN268YN0mTZpkK7uPjY3N/BGeNWtWnvvs2bMn\nH374YWYdyqFDhzh+/DixsbFUqFCBkJAQduzYwerVq3Ndf+LEiWzcuPGCv5xJAqx6hNmzZ5OSksL+\n/fvZvXs37dq1u2C56tWrs3TpUgCWLFlCw4YFNwdkjOHo0aNEREQUuOzl8sJE4bycrNvrolZbufIA\np04lAhAY6Mfs2X3ZsWMIQ4a0036rVanQunVrWrZsyeeff05wcDBz587l1VdfpVGjRrRo0YK2bdtm\n3nXyG38AAAqwSURBVILZsmVLJk2axL333kuTJk1o3rw5+/btu2CbY8aM4cyZMzRv3pxWrVplnmn/\n61//ok+fPlxzzTVUq5b/Sdg999zDJ598klnsBDBlyhTWrVtHy5Ytadq0aa5JqnHjxsTGxhIXFwfA\nyJEjee6552jdujXp6el57u/GG2/kvvvuo2PHjrRo0YI777yTuLg4evXqRXp6Ok2aNOHZZ5/NVrdw\nqZo1a8bdd99N06ZN6dWrF9OmTcssdnvkkUdYt24dAP/+97956qmnaNWqFaNHj+b999/P3EZERARP\nPvkks2bNombNmplFcuvXr6dDhw74+Xm+YEiM8a4+EyLrlTHrhiRAny+h0V0FLn/qVCLPPruYmTM3\nMHBga2bOvLUIolQKtm/fTpMmTewOo0SbOHEiYWFhbhfVlCTDhw/n1ltvpVu3bhfMy+2zJyLrjTGR\nl7Iv7zuVPl/0FFg+38WMMXz00UYaN57GzJkb8Pf3oXr1MLwtMSql8jZ48GACAy/9phZv1rx581yT\nhCd4X2U2zh/6CnmX4e3YcZKoqHksXfo3AF26RDBjxs00blypKAJUShWRoKAgBgwYYHcYtvi///u/\nItuX9yWKjFTrNY/mO2JiztGqVTSpqRlUqhTCO+/cyIAB+lyEsocxRj976v/bu/sYqcorjuPfHwju\ntgqK1Kay1QXlRWyBWLAbNS0UbYWGYBsCtRSraau0SivExrT0xab9g6YtqUCBbpCAiUqiSKUEtaSi\nWATZVXkTat2i0a1EqFAxiDSwp388zzLjOjt7d8rcmdk9n2QCc+feuWdOZu+Z55m556aqGLMmlVco\nWlXnHh3U1PRhxowR9Ogh5s27hn79iv/TMedyqaqqOnUylBcLlwaL16PI97PiQlRuoYgjiv3732X2\n7CeYOXM0Y8fWAlBfP8mvV+1KrqamhubmZg4ePFjqUFw30nqFu9OpMgvFkKmcPNnCkiWNzJ37JEeO\nHKep6RANDd9BkhcJVxZ69ep1Wq8y5lypFPVXT5Kuk/SypCZJHzobRcGC+PhOSYnOonvhrUHU1d3L\nrFmPceTIcSZNGsLq1VN9eO+cc0VQtBGFpJ7AH4BrgWagQdJaM9uTtdoEYHC8fRZYEv9t1xv/6cOY\nW6toaXmTmpo+LFw4gcmTh3qRcM65IinmiOIKoMnM9pnZf4FVwOQ260wG7ovt0rcC50jKexrnofeq\nkWDOnDr27r2N668f5kXCOeeKqJjfUQwA3si638yHRwu51hkA7M9eSdItQGtj+ONw9+7582H+/NMb\ncAXqD/y71EGUCc9Fhuciw3ORMbTQDSviy2wzqwfqASQ1FnoaelfjucjwXGR4LjI8FxmSGgvdtphT\nT/8CPpl1vyYu6+w6zjnnSqiYhaIBGCxpoKTewNeAtW3WWQvcGH/9VAe8Y2b72z6Rc8650ina1JOZ\nnZB0O/AE0BNYbmYvSZoZH18KrAcmAk3Ae8DNCZ66vuNVug3PRYbnIsNzkeG5yCg4FxXXZtw551y6\nKq/NuHPOuVR5oXDOOZdX2RaKYrX/qEQJcjE95mCXpGcljSxFnGnoKBdZ642RdELSlDTjS1OSXEga\nK2m7pJckPZ12jGlJ8DfSV9KfJe2IuUjyfWjFkbRc0gFJu9t5vLDjppmV3Y3w5fc/gUFAb2AHMLzN\nOhOBxwABdcBzpY67hLm4Ejg3/n9Cd85F1npPEn4sMaXUcZfwfXEOsAe4MN4/v9RxlzAXPwZ+Hf//\nMeAQ0LvUsRchF58DLgd2t/N4QcfNch1RFKX9R4XqMBdm9qyZHY53txLOR+mKkrwvAGYBq4EDaQaX\nsiS5+DrwiJm9DmBmXTUfSXJhwNkK/X7OIhSKE+mGWXxmtonw2tpT0HGzXAtFe609OrtOV9DZ1/kt\nwieGrqjDXEgaAHyF0GCyK0vyvhgCnCvpKUnPS7oxtejSlSQXi4BLgTeBXcAPzKwlnfDKSkHHzYpo\n4eGSkTSOUCiuLnUsJfR74C4za/FmkZwBfAYYD1QDWyRtNbN/lDaskvgSsB34AnAxsEHSM2Z2pLRh\nVYZyLRTe/iMj0euUNAJYBkwws7dTii1tSXIxGlgVi0R/YKKkE2b2p3RCTE2SXDQDb5vZUeCopE3A\nSKCrFYokubgZmGdhor5J0qvAMGBbOiGWjYKOm+U69eTtPzI6zIWkC4FHgBld/NNih7kws4FmVmtm\ntcDDwPe6YJGAZH8jjwJXSzpD0kcI3Zv3phxnGpLk4nXCyApJHyd0Ut2XapTloaDjZlmOKKx47T8q\nTsJc/Aw4D1gcP0mfsC7YMTNhLrqFJLkws72SHgd2Ai3AMjPL+bPJSpbwffFLYIWkXYRf/NxlZl2u\n/bikB4GxQH9JzcDPgV7w/x03vYWHc865vMp16sk551yZ8ELhnHMuLy8Uzjnn8vJC4ZxzLi8vFM45\n5/LyQuHKjqSTseNp6602z7q17XXK7OQ+n4rdR3dI2ixpaAHPMbO1TYakmyRdkPXYMknDT3OcDZJG\nJdjmjngehXMF8ULhytExMxuVdXstpf1ON7ORwErgN53dOJ67cF+8exNwQdZj3zazPaclykyci0kW\n5x2AFwpXMC8UriLEkcMzkl6ItytzrHOZpG1xFLJT0uC4/BtZy/8oqWcHu9sEXBK3HS/pRYVrfSyX\ndGZcPk/Snrif38Zld0u6U+EaGKOB++M+q+NIYHQcdZw6uMeRx6IC49xCVkM3SUskNSpcb+EXcdn3\nCQVro6SNcdkXJW2JeXxI0lkd7Md1c14oXDmqzpp2WhOXHQCuNbPLgWnAghzbzQTuMbNRhAN1s6RL\n4/pXxeUngekd7H8SsEtSFbACmGZmnyZ0MviupPMIHWovM7MRwK+yNzazh4FGwif/UWZ2LOvh1XHb\nVtMIvakKifM6ILs9ydx4Rv4I4POSRpjZAkLH1HFmNk5Sf+AnwDUxl43AnA7247q5smzh4bq9Y/Fg\nma0XsCjOyZ8ktNBuawswV1IN4ToMr0gaT+ig2hDbm1TT/nUq7pd0DHiNcE2LocCrWf2zVgK3EVpW\nvw/cK2kdsC7pCzOzg5L2xT47rxAa022Oz9uZOHsTrquQnaepkm4h/F1/AhhOaN+RrS4u3xz305uQ\nN+fa5YXCVYrZwFuE7qc9CAfqDzCzByQ9B3wZWC/pVkJfn5Vm9qME+5huZo2tdyT1y7VS7C10BaHJ\n3BTgdkL76qRWAVOBvwNrzMwUjtqJ4wSeJ3w/sRD4qqSBwJ3AGDM7LGkFUJVjWwEbzOyGTsTrujmf\nenKVoi+wP15sZgah+dsHSBoE7IvTLY8SpmD+CkyRdH5cp5+kixLu82WgVtIl8f4M4Ok4p9/XzNYT\nCliua5S/C5zdzvOuIVxp7AZC0aCzccZ22T8F6iQNA/oAR4F3FLqjTmgnlq3AVa2vSdJHJeUanTl3\nihcKVykWA9+UtIMwXXM0xzpTgd2StgOfIlzycQ9hTv4vknYCGwjTMh0ys/cJ3TUfil1HW4ClhIPu\nuvh8fyP3HP8KYGnrl9ltnvcwod33RWa2LS7rdJzxu4/fAT80sx3Ai4RRygOE6axW9cDjkjaa2UHC\nL7IejPvZQsinc+3y7rHOOefy8hGFc865vLxQOOecy8sLhXPOuby8UDjnnMvLC4Vzzrm8vFA455zL\nywuFc865vP4HOEs53rNDh+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20766040ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAIBCAYAAADK2ozvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiwaJElSIf8f5KM5vxMjCTkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2070eea3be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>split</th>\n",
       "      <th>true_y</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567403</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>573854</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>577824</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593504</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598961</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>609041</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>609101</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>611233</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>612293</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>617451</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>621573</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>628081</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>628731</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>628791</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>629491</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>630194</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>631444</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>638332</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>642451</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>642663</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>643451</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>649501</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>650271</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>650311</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>650482</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>652681</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>653561</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>655662</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>655791</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>656162</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>1282166</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>1282256</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>1282436</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>1282496</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>1285046</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>1286404</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>1288963</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>1289216</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>1290265</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>1290575</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>1290626</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6677</th>\n",
       "      <td>1291715</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>1293125</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>1294085</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>1294736</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>1297712</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>1297712</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>1298246</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>1298246</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.393674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>1298386</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>1298386</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>1303846</td>\n",
       "      <td>Test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>1303846</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>1306076</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>1309346</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>1311386</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>1311386</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>1322366</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>1322366</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>1324936</td>\n",
       "      <td>Train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6696 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       serial       split  true_y    pred_y\n",
       "0      567403  Validation       0  0.792220\n",
       "1      573854  Validation       0  0.119861\n",
       "2      577824  Validation       0  0.485571\n",
       "3      593504  Validation       0  0.181170\n",
       "4      598961  Validation       1  0.336047\n",
       "5      609041  Validation       1  0.853749\n",
       "6      609101  Validation       0  0.222492\n",
       "7      611233  Validation       0  0.125600\n",
       "8      612293  Validation       0  0.116665\n",
       "9      617451  Validation       0  0.073494\n",
       "10     621573  Validation       0  0.119527\n",
       "11     628081  Validation       0  0.217595\n",
       "12     628731  Validation       0  0.247399\n",
       "13     628791  Validation       1  0.187659\n",
       "14     629491  Validation       1  0.232895\n",
       "15     630194  Validation       0  0.248075\n",
       "16     631444  Validation       1  0.868662\n",
       "17     638332  Validation       0  0.102384\n",
       "18     642451  Validation       0  0.259469\n",
       "19     642663  Validation       0  0.119698\n",
       "20     643451  Validation       0  0.116409\n",
       "21     649501  Validation       0  0.247520\n",
       "22     650271  Validation       0  0.116665\n",
       "23     650311  Validation       0  0.202849\n",
       "24     650482  Validation       0  0.506113\n",
       "25     652681  Validation       1  0.376194\n",
       "26     653561  Validation       0  0.081996\n",
       "27     655662  Validation       0  0.119720\n",
       "28     655791  Validation       0  0.253998\n",
       "29     656162  Validation       0  0.221000\n",
       "...       ...         ...     ...       ...\n",
       "6666  1282166       Train       1  0.817112\n",
       "6667  1282256       Train       0  0.116810\n",
       "6668  1282436        Test       0  0.147951\n",
       "6669  1282496       Train       0  0.224179\n",
       "6670  1285046       Train       1  0.777904\n",
       "6671  1286404       Train       0  0.115295\n",
       "6672  1288963       Train       1  0.732593\n",
       "6673  1289216       Train       1  0.871530\n",
       "6674  1290265       Train       1  0.782781\n",
       "6675  1290575       Train       0  0.102215\n",
       "6676  1290626       Train       0  0.175481\n",
       "6677  1291715       Train       0  0.247399\n",
       "6678  1293125        Test       0  0.257380\n",
       "6679  1294085       Train       1  0.074539\n",
       "6680  1294736       Train       1  0.287936\n",
       "6681  1297712        Test       0  0.211781\n",
       "6682  1297712       Train       0  0.211781\n",
       "6683  1298246        Test       1  0.393674\n",
       "6684  1298246       Train       1  0.393674\n",
       "6685  1298386       Train       0  0.253998\n",
       "6686  1298386       Train       0  0.253998\n",
       "6687  1303846        Test       0  0.189916\n",
       "6688  1303846       Train       0  0.189916\n",
       "6689  1306076       Train       0  0.172922\n",
       "6690  1309346       Train       1  0.287936\n",
       "6691  1311386        Test       1  0.854827\n",
       "6692  1311386       Train       1  0.854827\n",
       "6693  1322366       Train       0  0.303199\n",
       "6694  1322366       Train       0  0.303199\n",
       "6695  1324936       Train       0  0.081920\n",
       "\n",
       "[6696 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model testing\n",
    "val_lstm(sample_df, model_lstm.model, full_array_x, sample_df['y'], batch_size = 50, cutoff = 0.40,result_csv_save_name='lstm_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
